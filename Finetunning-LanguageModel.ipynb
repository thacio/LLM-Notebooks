{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook é um tutorial de fine-tunning em modelos de linguagem.\n",
        "\n",
        "São suportados os modelos do tipo decoder e encoder-decoder. Estes dois modelos têm textos como entrada e saída. O código não suporta modelos do tipo encoder, que têm como entrada textos e geram como saída geralmente um vetor numérico ou um número (embeddings ou probabilidades das classes).\n",
        "\n",
        "```\n",
        "Modelos do tipo decoder: GPT\n",
        "Modelos do tipo encoder-decoder: T5\n",
        "Modelos do tipo encoder: BERT, DeBERTa\n",
        "```"
      ],
      "metadata": {
        "id": "ChRZNgj0Ytpo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTzNimfiFamU"
      },
      "source": [
        "# Inicialização das variáveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tphHGol9EjPU"
      },
      "outputs": [],
      "source": [
        "RESUME_FROM_CHECKPOINT = False\n",
        "\n",
        "inserir_beginoftext_token = True # Inserir um token '<|target_bos|>' separando o prompt da resposta nos modelos tipo decoder (GPT, llama)\n",
        "MAX_TOKEN_GENERATION_LENGTH=60 # O número de tokens que será gerado, no máximo, no step de validação\n",
        "\n",
        "output_dir=\"/content/fine-tuned-model\"\n",
        "\n",
        "## Esses valores devem ser definidos para cada modelo\n",
        "## Caso retorne o erro CUDA out of memory, diminuia o batch size\n",
        "# model_type='encoder'\n",
        "# model_type='encoder-decoder'\n",
        "# model_type='decoder'\n",
        "# BATCH_SIZE = 16\n",
        "# EVAL_BATCH_SIZE=16\n",
        "# dropout_rate=0.1\n",
        "# fp16=True # Treina o modelo em fp16. É a metade do tempo de treino, porém pode diminuir a precisão do modelo\n",
        "\n",
        "# transformer_model_name='thacio/ult5-pt-small'; model_type='encoder-decoder'; dropout_rate=0.0; BATCH_SIZE = 16; EVAL_BATCH_SIZE=16; fp16=True; #prefix_input='<|NLU|>' # '<|NLG|>'\n",
        "transformer_model_name='tgsc/debertina-base'; model_type='encoder'; BATCH_SIZE = 8; EVAL_BATCH_SIZE=8; fp16=False\n",
        "\n",
        "gradient_accumulation_steps = int(round(128//BATCH_SIZE))\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znCm5mx5DIBI",
        "outputId": "c4eae3a3-2894-4391-b348-cf554b535e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul 19 19:35:32 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "cpu_count: 2\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "num_proc = multiprocessing.cpu_count()\n",
        "print('cpu_count:',num_proc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGBw38YAFgyK",
        "outputId": "3ffbae6a-7ae6-4714-9077-6e9036cb34de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Collecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "Successfully installed datasets-2.13.1 dill-0.3.6 huggingface-hub-0.16.4 multiprocess-0.70.14 xxhash-3.2.0\n",
            "Collecting transformers==4.30.2\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.2)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.30.2)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: tokenizers, safetensors, transformers, accelerate\n",
            "Successfully installed accelerate-0.21.0 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.0 responses-0.18.0\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=8a67bdb5366cdb6611d57e3aa667fa7daa972e65e81692a32306fb7253e15824\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers==4.30.2 accelerate\n",
        "!pip install sentencepiece\n",
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carrega o tokenizer"
      ],
      "metadata": {
        "id": "PYokeH9Dbb5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers as transformers\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(transformer_model_name,use_auth_token='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')\n",
        "\n",
        "# Nos modelos decoder, adicionaremos um token separando a entrada da resposta para podermos identificar e dar split na string na méetrica de validação\n",
        "if model_type=='decoder':\n",
        "    tokenizer.add_special_tokens({'pad_token': '<|pad|>'}) # Adicionaremos um token de pad caso o modelo não tenha (não afeta o resultado)\n",
        "\n",
        "    if inserir_beginoftext_token:\n",
        "        target_bos_token='<|target_bos|>'\n",
        "        tokenizer.add_special_tokens({ \"additional_special_tokens\": [target_bos_token] })\n",
        "\n",
        "if model_type=='encoder' and tokenizer.sep_token==None:\n",
        "    tokenizer.add_special_tokens({'sep_token': tokenizer.eos_token})"
      ],
      "metadata": {
        "id": "tTnSKik6beq3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "d521787d1cc342d9b38a9088144f6e06",
            "e9c976e229d2482da023213957890c3b",
            "96dfd03ca67d478b9475ac46e351b0d0",
            "223f037d73574effa62a7e7b1e1ccc09",
            "1371b50a2c414236abd3d2187d9b6efe",
            "15ab93fdfd4c4a90917c321a922189a6",
            "a95640943d224bbabbb46d6207001989",
            "5276abf563064206ac6d271039a66186",
            "88a41276cd554ade940d5fd7c214a9d9",
            "d28834f480054ede9e9af1d6c00fb091",
            "96af53daf9944aa887b8b9b086fe0903",
            "495c3b439bfd414a8b6bb6b66f6a6547",
            "11b530516bbc4684bf711642606ee620",
            "2fa2a160e15e4e55a311aec16db0cf78",
            "2f814f0fc0e9454691abe4ac7557cf88",
            "d982aa17b8354b7385e9138953645be3",
            "3b6ea72cd8694771ba2684db6886f8a6",
            "71830082d1c148a799eab8c645a1d9ac",
            "cfa6d92fe21f44feb1cadcfc8d857dc5",
            "db99058a1e02433fa0eb0845e96cdaa1",
            "4feea995684344838011dcd2d0541e4d",
            "8c473e4bfc54466d85cb3db2e4d90373",
            "8d2348bfdfef4db58e3226340bcdeb34",
            "f0d3960d491b4ce598d267dc1b31d290",
            "3761085aabf34491a490b78d52733084",
            "64451c7168354169aa1149973bb03c5f",
            "1ef721cfd50a4f3a994bf5dfc15b4396",
            "f61735352c2d45f6a0bfe6d50dc63084",
            "10afd0c1940f447cb044552515ca4b0c",
            "80ab21a5c7074c67a268852f39a17611",
            "490a76ab50fc4e34a3c878cafa12d5f7",
            "89df2bf82207486d859e8f3bfc52dce1",
            "2e0f9c0eabd949db91117c2f8b269050"
          ]
        },
        "outputId": "c4c90a4a-4e6d-44a0-d2bc-68bdbde5926e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d521787d1cc342d9b38a9088144f6e06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/606 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "495c3b439bfd414a8b6bb6b66f6a6547"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading spm.model:   0%|          | 0.00/816k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d2348bfdfef4db58e3226340bcdeb34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carrega o modelo"
      ],
      "metadata": {
        "id": "C5N2ZCTKq8N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "if model_type=='encoder-decoder':\n",
        "    # model = AutoModelForSeq2SeqLM.from_pretrained(transformer_model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(transformer_model_name,dropout_rate=dropout_rate)\n",
        "elif model_type=='decoder':\n",
        "    model = AutoModelForCausalLM.from_pretrained(transformer_model_name)\n",
        "elif model_type=='encoder':\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(transformer_model_name)\n",
        "else:\n",
        "    raise ValueError('tipo de arquitetura deve ser \"encoder\", \"encoder-decoder\" ou \"decoder\"')\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.max_length=MAX_TOKEN_GENERATION_LENGTH\n",
        "\n",
        "# context_length é o tamanho máximo do modelo\n",
        "try:\n",
        "    context_length=model.config.n_positions\n",
        "except:\n",
        "    context_length=model.config.max_position_embeddings\n",
        "\n",
        "print(model.config)\n",
        "model_size = sum(t.numel() for t in model.parameters())\n",
        "print(f\"Model size: {model_size/1000**2:.1f}M parameters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746,
          "referenced_widgets": [
            "1b051fae17374d72bb88de17e8a4cc59",
            "76c4acb24c0e4862bfe2ef30c7e49c47",
            "70e345cc035248269cbf8d2e1a25097e",
            "6b6a97fb6f75494fab5956cc44d7e4f7",
            "298340109012411c8aa9caafa3acd10c",
            "2f86fd4880384495b0756a39af14822f",
            "ac0b1f55aa62407eb57c4c944720b4be",
            "9ced7fd6afdc4dcdb4ba080fae20da85",
            "d4f5dcb6a3224f4f91922b26f0c29662",
            "da604443eb85406e973877926abd2920",
            "f1ea91c9d09d4e02957d2a971049f441"
          ]
        },
        "id": "r-XWDOhKq8mu",
        "outputId": "cd4dabf0-60a2-4f7f-b230-6ac93717512f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/272M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b051fae17374d72bb88de17e8a4cc59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at tgsc/debertina-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at tgsc/debertina-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DebertaV2Config {\n",
            "  \"_name_or_path\": \"tgsc/debertina-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.30.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 32001\n",
            "}\n",
            "\n",
            "Model size: 110.6M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cria e processa o dataset"
      ],
      "metadata": {
        "id": "4amVUH6_Ocen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Faz o download dos datasets.\n",
        "\n",
        "Um arquivo tsv é um arquivo csv, porém usa como separador a tabulação \\t em vez de vírgula"
      ],
      "metadata": {
        "id": "7c5dNM_XQJmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!wget 'https://github.com/ju-resplande/PLUE/raw/master/datasets/MRPC/train.tsv' -O train.tsv\n",
        "!wget 'https://github.com/ju-resplande/PLUE/raw/master/datasets/MRPC/dev.tsv' -O validation.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwybZlhjOgLw",
        "outputId": "32b6c3f0-74c8-43d1-82f3-e7d4da23743b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-19 19:36:42--  https://github.com/ju-resplande/PLUE/raw/master/datasets/MRPC/train.tsv\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ju-resplande/PLUE/master/datasets/MRPC/train.tsv [following]\n",
            "--2023-07-19 19:36:42--  https://raw.githubusercontent.com/ju-resplande/PLUE/master/datasets/MRPC/train.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1011446 (988K) [text/plain]\n",
            "Saving to: ‘train.tsv’\n",
            "\n",
            "train.tsv           100%[===================>] 987.74K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-07-19 19:36:42 (28.4 MB/s) - ‘train.tsv’ saved [1011446/1011446]\n",
            "\n",
            "--2023-07-19 19:36:43--  https://github.com/ju-resplande/PLUE/raw/master/datasets/MRPC/dev.tsv\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ju-resplande/PLUE/master/datasets/MRPC/dev.tsv [following]\n",
            "--2023-07-19 19:36:43--  https://raw.githubusercontent.com/ju-resplande/PLUE/master/datasets/MRPC/dev.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 114080 (111K) [text/plain]\n",
            "Saving to: ‘validation.tsv’\n",
            "\n",
            "validation.tsv      100%[===================>] 111.41K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-07-19 19:36:43 (5.93 MB/s) - ‘validation.tsv’ saved [114080/114080]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carrega o dataset pelo pandas"
      ],
      "metadata": {
        "id": "D94NhlPKRBgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "num_labels = 2 # Quantidade de classes contidas no dataset\n",
        "\n",
        "# O arquivo dá erro ao carregar algumas linhas, então utilizaremos on_bad_lines='skip' para pulá-las\n",
        "df_train = pd.read_csv('train.tsv', sep='\\t', header=0,  on_bad_lines='skip')\n",
        "df_validation = pd.read_csv('validation.tsv', sep='\\t', header=0, on_bad_lines='skip')\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fWxkTYeURI0G",
        "outputId": "16287273-4118-4ab8-97bf-a0b845e6c5a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Quality    #1 ID    #2 ID  \\\n",
              "0        1   702876   702977   \n",
              "1        0  2108705  2108831   \n",
              "2        1  1330381  1330521   \n",
              "3        0  3344667  3344648   \n",
              "4        1  1236820  1236712   \n",
              "\n",
              "                                           #1 String  \\\n",
              "0  Amrozi acusou seu irmão, a quem chamou de \"tes...   \n",
              "1  Yucaipa possuía a Dominick 's antes de vender ...   \n",
              "2  Eles publicaram um anúncio na Internet em 10 d...   \n",
              "3  Por volta de 0335 GMT, as ações da Tab subiram...   \n",
              "4  As ações subiram US $ 2,11, ou cerca de 11%, p...   \n",
              "\n",
              "                                           #2 String  \n",
              "0  Referindo-se a ele como apenas \"a testemunha\",...  \n",
              "1  Yucaipa comprou a Dominick em 1995 por US $ 69...  \n",
              "2  Em 10 de junho, os proprietários do navio havi...  \n",
              "3  As ações da Tab saltaram 20 centavos, ou 4,6%,...  \n",
              "4  As ações da PG & E Corp subiram US $ 1,63 ou 8...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-7411f8b1-0000-46d3-b7ba-753c27a4e31d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quality</th>\n",
              "      <th>#1 ID</th>\n",
              "      <th>#2 ID</th>\n",
              "      <th>#1 String</th>\n",
              "      <th>#2 String</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>702876</td>\n",
              "      <td>702977</td>\n",
              "      <td>Amrozi acusou seu irmão, a quem chamou de \"tes...</td>\n",
              "      <td>Referindo-se a ele como apenas \"a testemunha\",...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2108705</td>\n",
              "      <td>2108831</td>\n",
              "      <td>Yucaipa possuía a Dominick 's antes de vender ...</td>\n",
              "      <td>Yucaipa comprou a Dominick em 1995 por US $ 69...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1330381</td>\n",
              "      <td>1330521</td>\n",
              "      <td>Eles publicaram um anúncio na Internet em 10 d...</td>\n",
              "      <td>Em 10 de junho, os proprietários do navio havi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3344667</td>\n",
              "      <td>3344648</td>\n",
              "      <td>Por volta de 0335 GMT, as ações da Tab subiram...</td>\n",
              "      <td>As ações da Tab saltaram 20 centavos, ou 4,6%,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1236820</td>\n",
              "      <td>1236712</td>\n",
              "      <td>As ações subiram US $ 2,11, ou cerca de 11%, p...</td>\n",
              "      <td>As ações da PG &amp; E Corp subiram US $ 1,63 ou 8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7411f8b1-0000-46d3-b7ba-753c27a4e31d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-624a5fa3-dcb2-4f2f-a83b-fe5f962d500d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-624a5fa3-dcb2-4f2f-a83b-fe5f962d500d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-624a5fa3-dcb2-4f2f-a83b-fe5f962d500d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7411f8b1-0000-46d3-b7ba-753c27a4e31d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7411f8b1-0000-46d3-b7ba-753c27a4e31d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carrega o dataset na biblioteca datasets do huggingface\n",
        "\n",
        "https://huggingface.co/docs/datasets/loading"
      ],
      "metadata": {
        "id": "VsbKG5ieQVpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds_train = datasets.Dataset.from_pandas(df_train)\n",
        "ds_validation = datasets.Dataset.from_pandas(df_validation)\n",
        "\n",
        "ds = datasets.DatasetDict({\n",
        "    'train' : ds_train,\n",
        "    'validation' : ds_validation\n",
        "    })\n",
        "\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z6o0o5hQWXW",
        "outputId": "1133b976-8211-47e5-ff92-ffda26bf40ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Quality', '#1 ID', '#2 ID', '#1 String', '#2 String'],\n",
              "        num_rows: 3549\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['Quality', '#1 ID', '#2 ID', '#1 String', '#2 String'],\n",
              "        num_rows: 388\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('exemplo do dataset')\n",
        "ds['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znX9S7DXSyMd",
        "outputId": "69a6dd0f-5dc1-45a7-8390-6809c252d153"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exemplo do dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Quality': 1,\n",
              " '#1 ID': 702876,\n",
              " '#2 ID': 702977,\n",
              " '#1 String': 'Amrozi acusou seu irmão, a quem chamou de \"testemunha\", de distorcer deliberadamente suas evidências.',\n",
              " '#2 String': 'Referindo-se a ele como apenas \"a testemunha\", Amrozi acusou seu irmão de distorcer deliberadamente suas evidências.'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converte o dataset para textos de input e labels\n",
        "\n",
        "Os modelos do tipo decoder (gpt2) e enconder-decoder (t5) geram textos, então devemos converter tudo em texto. Se por acaso os rótulos forem numéricos (0,1,...), também devem ser convertido para textos. Textos representativos dos rótulos costumam gerar melhores resultados do que rótulos de string '0' e '1'.\n",
        "\n",
        "Já os modelos do tipo encoder (BERT) geralmente tem como saída as classes númericas. (há exceção e tem como usar o BERT como decoder, porém não é usual)\n",
        "\n",
        "---\n",
        "\n",
        "O dataset MRPC é composto da sentença 1 e sentença 2, e o rótulo é se as sentenças são paráfrases ou não.\n",
        "\n",
        "Dessa forma, faremos a transformação do exemplo:\n",
        "\n",
        "```\n",
        "{\n",
        "'#1 String': 'Amrozi acusou seu irmão, a quem chamou de \"testemunha\", de distorcer deliberadamente suas evidências.',\n",
        "'#2 String': 'Referindo-se a ele como apenas \"a testemunha\", Amrozi acusou seu irmão de distorcer deliberadamente suas evidências.'\n",
        "'Quality': 1\n",
        "}\n",
        "```\n",
        "\n",
        "Para\n",
        "\n",
        "```\n",
        "{\n",
        "'text' : 'mrpc sentença 1: Amrozi acusou seu irmão, a quem chamou de \"testemunha\", de distorcer deliberadamente suas evidências. sentença 2: Referindo-se a ele como apenas \"a testemunha\", Amrozi acusou seu irmão de distorcer deliberadamente suas evidências.'\n",
        "'label': 'equivalentes'\n",
        "}\n",
        "```\n",
        "com acréscimo dos tokens necessários (eos_token e taget_bos_token em decoders)"
      ],
      "metadata": {
        "id": "CrkGqkVYXK1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para fazer essa conversão, usaremos a função map do huggingface datasets.\n",
        "\n",
        "https://huggingface.co/docs/datasets/process"
      ],
      "metadata": {
        "id": "6l0fwJnrYnaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função map para decoders (gpt2, llama)"
      ],
      "metadata": {
        "id": "FYyND0e8ZJtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mrpc_map_dec_function(examples):\n",
        "    new_examples = { 'text':[], 'labels':[]}\n",
        "\n",
        "    first_key=list(examples.keys())[0]\n",
        "    for i in range(0,len(examples[first_key])):\n",
        "        if examples[\"#1 String\"][i]==None or examples[\"#2 String\"][i]==None or examples['Quality'][i]==None:\n",
        "            continue\n",
        "\n",
        "        input=f'mrpc sentença 1: {examples[\"#1 String\"][i]}'\n",
        "        input+=f' sentença 2: {examples[\"#2 String\"][i]}'\n",
        "        if examples['Quality'][i] == 0:\n",
        "            label = 'diferentes'\n",
        "        elif examples['Quality'][i] == 1:\n",
        "            label = 'equivalentes'\n",
        "\n",
        "        if inserir_beginoftext_token:\n",
        "            input += target_bos_token\n",
        "\n",
        "        # adicionamos o o token de fim de texto ao label\n",
        "        label += tokenizer.eos_token\n",
        "\n",
        "        new_examples['text'].append(input)\n",
        "        new_examples['labels'].append(label)\n",
        "\n",
        "    return new_examples\n",
        "\n",
        "if model_type=='decoder':\n",
        "    ds_processado = ds.map(\n",
        "          mrpc_map_dec_function,\n",
        "          batched=True,\n",
        "          batch_size=1_000,\n",
        "          remove_columns=ds['train'].column_names,\n",
        "          num_proc=2\n",
        "      )\n",
        "    print(ds_processado)\n",
        "    print(ds_processado['train'][0])"
      ],
      "metadata": {
        "id": "sqT6OS2SXMzy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Função map para modelos encoder-decoders (t5, ul2)"
      ],
      "metadata": {
        "id": "HxeKws6IZONT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a função de map para ser aplicada ao dataset\n",
        "def mrpc_map_enc_dec_function(examples):\n",
        "    new_examples = { 'text':[], 'labels':[]}\n",
        "\n",
        "    first_key=list(examples.keys())[0]\n",
        "    for i in range(0,len(examples[first_key])):\n",
        "        if examples[\"#1 String\"][i]==None or examples[\"#2 String\"][i]==None or examples['Quality'][i]==None:\n",
        "            continue\n",
        "\n",
        "        input=f'mrpc sentença 1: {examples[\"#1 String\"][i]}'\n",
        "        input+=f' sentença 2: {examples[\"#2 String\"][i]}'\n",
        "        input+=' As duas sentenças são equivalentes ou diferentes?'\n",
        "        if examples['Quality'][i] == 0:\n",
        "            label = 'diferentes'\n",
        "        elif examples['Quality'][i] == 1:\n",
        "            label = 'equivalentes'\n",
        "\n",
        "        label += tokenizer.eos_token\n",
        "\n",
        "        if 'prefix_input' in globals() and prefix_input!=None and len(prefix_input)>0:\n",
        "            input = prefix_input + input\n",
        "\n",
        "        new_examples['text'].append(input)\n",
        "        new_examples['labels'].append(label)\n",
        "\n",
        "    return new_examples\n",
        "\n",
        "# aplica a função\n",
        "if model_type=='encoder-decoder':\n",
        "    ds_processado = ds.map(\n",
        "          mrpc_map_enc_dec_function,\n",
        "          batched=True,\n",
        "          batch_size=1_000,\n",
        "          remove_columns=ds['train'].column_names,\n",
        "          num_proc=2\n",
        "      )\n",
        "    print(ds_processado)\n",
        "    print(ds_processado['train'][0])"
      ],
      "metadata": {
        "id": "8fOz_3xIZaod"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função map para os modelos encoders"
      ],
      "metadata": {
        "id": "d5eG39pYvbZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a função de map para ser aplicada ao dataset\n",
        "def mrpc_map_enc_dec_function(examples):\n",
        "    new_examples = { 'text':[], 'labels':[]}\n",
        "\n",
        "    first_key=list(examples.keys())[0]\n",
        "    for i in range(0,len(examples[first_key])):\n",
        "\n",
        "        if examples[\"#1 String\"][i]==None or examples[\"#2 String\"][i]==None or examples['Quality'][i]==None:\n",
        "            continue\n",
        "\n",
        "        input= examples[\"#1 String\"][i] + tokenizer.sep_token + examples[\"#2 String\"][i]\n",
        "        label = examples['Quality'][i]\n",
        "\n",
        "        new_examples['text'].append(input)\n",
        "        new_examples['labels'].append(label)\n",
        "\n",
        "    return new_examples\n",
        "\n",
        "# aplica a função\n",
        "if model_type=='encoder':\n",
        "    ds_processado = ds.map(\n",
        "          mrpc_map_enc_dec_function,\n",
        "          batched=True,\n",
        "          batch_size=1_000,\n",
        "          remove_columns=ds['train'].column_names,\n",
        "          num_proc=2\n",
        "      )\n",
        "    print(ds_processado)\n",
        "    print(ds_processado['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228,
          "referenced_widgets": [
            "0cb62eb9b552489ab9d3986e9abe7e74",
            "528b822601c64647a4c659ac04dda0c2",
            "2d04369bacad446e839ccc60dc5b55a2",
            "4f26dfe0c6e249ca87394776d9a9a5ce",
            "242c8d799ffc4274b3ab9f5bcff91077",
            "9240628e60cf4a3c831a9432342e845e",
            "943ffe94b09642fda92b5736671297c9",
            "8f93f0b059ff4020aed24ac93484864c",
            "b0ee6ebd49cb46e9aa06f48657155df1",
            "0e4150f4d05b416fab0cd72790ff0feb",
            "e3d43acde3c1493fbd7c743b2e2c8a53",
            "92b240804fbc4e2cae71d458a6efd94c",
            "41789bbffa94461ea116d9a69dc38d48",
            "93fcd9dacc534c65899073f627cb6874",
            "a2e066e4f24247338d4aff20cab2388b",
            "1397dcfb9ffc4edaa58e8a8234133941",
            "903ca7610b864932bb972d816407a693",
            "2a67508a15534e2e86f7e70c6a4f221a",
            "a2cf92ae5ccd469d96e05ab68d4a113d",
            "5e873026dd3049938df61fef2c298751",
            "1c569737a7e04323ae399f33941558ca",
            "40e0e72a06674e94af182d451a8eb1ca"
          ]
        },
        "id": "lCI0A1U9vgr8",
        "outputId": "8fbc42ea-8bb9-4bb6-86ea-7dd0f1e504bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/3549 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cb62eb9b552489ab9d3986e9abe7e74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92b240804fbc4e2cae71d458a6efd94c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'labels'],\n",
            "        num_rows: 3532\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'labels'],\n",
            "        num_rows: 387\n",
            "    })\n",
            "})\n",
            "{'text': 'Amrozi acusou seu irmão, a quem chamou de \"testemunha\", de distorcer deliberadamente suas evidências.[SEP]Referindo-se a ele como apenas \"a testemunha\", Amrozi acusou seu irmão de distorcer deliberadamente suas evidências.', 'labels': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokeniza o dataset"
      ],
      "metadata": {
        "id": "wNFmOqH1gxH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_validation_ds = False\n",
        "def tokenize_dataset(examples):\n",
        "\n",
        "    examples['input_ids']=tokenizer(examples['text'],\n",
        "                      return_attention_mask=False,\n",
        "                      truncation=True,\n",
        "                      max_length=context_length,\n",
        "                      )['input_ids']\n",
        "\n",
        "    if model_type!='encoder':\n",
        "        examples['labels']=tokenizer(examples['labels'],\n",
        "                          return_attention_mask=False,\n",
        "                          truncation=True,\n",
        "                          max_length=context_length,\n",
        "                          )['input_ids']\n",
        "\n",
        "        # Insere o eos_token_id caso não tenha sido inserido anteriormente\n",
        "        for i, label in enumerate(examples['labels']):\n",
        "            try:\n",
        "                if label[len(label)-1]!=tokenizer.eos_token_id:\n",
        "                    examples['labels'][i] += [tokenizer.eos_token_id]\n",
        "            except:\n",
        "                # Caso por erro do dataset não haja label\n",
        "                examples['labels'][i] = [tokenizer.eos_token_id]\n",
        "                pass\n",
        "            # Nos decoders Nos datasets de validação, precisamos inseri\n",
        "            if model_type=='decoder' and is_validation_ds:\n",
        "                examples['labels'][i] = [500_000] + label\n",
        "\n",
        "    return examples\n",
        "\n",
        "ds_tokenizado = datasets.DatasetDict({'train':None, 'validation': None})\n",
        "\n",
        "ds_tokenizado['train'] = ds_processado['train'].map(\n",
        "    tokenize_dataset,\n",
        "    batched=True,\n",
        "    batch_size=1_000,\n",
        "    num_proc=2,\n",
        "    remove_columns=['text']\n",
        ")\n",
        "\n",
        "is_validation_ds = True\n",
        "ds_tokenizado['validation'] = ds_processado['validation'].map(\n",
        "    tokenize_dataset,\n",
        "    batched=True,\n",
        "    batch_size=1_000,\n",
        "    num_proc=2,\n",
        "    remove_columns=['text']\n",
        ")\n",
        "is_validation_ds = False\n",
        "\n",
        "print(ds_tokenizado)\n",
        "print(ds_tokenizado['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228,
          "referenced_widgets": [
            "8c8b712dc7d04eaaafae8a2be162d226",
            "8002379101d24dc39ea6c2ecac437107",
            "5c425aa7686a476295517ba02f21710a",
            "5cb9efe1e8124eb4a1f3e2f9100c2f49",
            "2778eef18f314bcd98af15f0b6daaa23",
            "d4a058b843ad4c399db57a4d2b198dc1",
            "72853bc8f687494bb6ffc9d2096f49da",
            "2ebaa628d439466dbaf0b7270f2ba744",
            "0d8ebe3211ee43c29283a9390d1b7e6e",
            "9e01c202baee46378411926181bd20a0",
            "425d3fceb2d74789bf5f956a79c48cb6",
            "c759a27928ac4a48a2a2afdd16379f60",
            "02955cadce084c88bdb82a6592ff12f4",
            "04cdd2b5f4a8433bb4d660fdb01a133d",
            "6a0bf3abb249427188ebdaad3e86fe2d",
            "133e4a50a5e3437aada09ae5aa203fd8",
            "735b34ecc0a64283a746b59f63d9f3b7",
            "96683dfbc1854c11b04dc343709ab79a",
            "a896b145d75f4a62b47f48beb0428c6a",
            "8096558a955747cabb23abf134936213",
            "0a28bb11984c4240a38dbb89945de979",
            "af7df589528b4ab89e0adeca0ad18db1"
          ]
        },
        "id": "6WN39BKahKkK",
        "outputId": "717cda7b-b088-41ee-b6c2-eb723029e858"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/3532 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c8b712dc7d04eaaafae8a2be162d226"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/387 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c759a27928ac4a48a2a2afdd16379f60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['labels', 'input_ids'],\n",
            "        num_rows: 3532\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['labels', 'input_ids'],\n",
            "        num_rows: 387\n",
            "    })\n",
            "})\n",
            "{'labels': 1, 'input_ids': [1, 2743, 573, 1584, 16305, 316, 1131, 260, 268, 1042, 3478, 261, 300, 1185, 5099, 337, 2279, 382, 261, 9144, 304, 1998, 23310, 410, 5371, 263, 2, 512, 7495, 344, 275, 302, 268, 346, 297, 442, 300, 306, 8837, 382, 2743, 573, 1584, 16305, 316, 1131, 261, 9144, 304, 1998, 23310, 410, 5371, 263, 2]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cria a métrica de validação do dataset"
      ],
      "metadata": {
        "id": "aKU7rUqKj20s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Métrica de avaliação do dataset\n",
        "\n",
        "Par ao dataset MRPC, usaremos a acurácia, ou seja, o acerto exato do rótulo"
      ],
      "metadata": {
        "id": "yEwkAkdFkih_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "def mrpc_metric(predictions,labels):\n",
        "    exact_match_metric = load(\"exact_match\")\n",
        "    result = exact_match_metric.compute(predictions=predictions,references=labels)\n",
        "    return {'mrpc_acc': result['exact_match']}"
      ],
      "metadata": {
        "id": "UriMY_ZOkAt-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de computo da métrica com geração de texto\n",
        "\n",
        "No caso de decoders, a função da métrica de avaliação recebe o texto inteiro 'input + labels', então precisamos processar a string recebida pela função para separar o input do label para, em seguida, calcular a métrica"
      ],
      "metadata": {
        "id": "fI48SeJrj6pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    result = {}\n",
        "\n",
        "    if model_type=='encoder':\n",
        "        return mrpc_metric(predictions,labels)\n",
        "\n",
        "    predictions=list(predictions)\n",
        "    labels=list(labels)\n",
        "\n",
        "    if model_type=='decoder':\n",
        "        target_bos_token_id = tokenizer.convert_tokens_to_ids(target_bos_token)\n",
        "\n",
        "        for i in range(len(predictions)):\n",
        "            # # Split nos  tokens gerados considerando o target_bos_token para identificar o input e o label\n",
        "            index = np.where(predictions[i] == target_bos_token_id)[0][0]\n",
        "            predictions[i] = predictions[i][index+1:] # texto gerado após o input\n",
        "\n",
        "    for i in range(0,len(labels)):\n",
        "        # remove  os ids que não podem ser decodificados\n",
        "        labels[i] = list(filter(lambda x: x!= -100, labels[i]))\n",
        "        predictions[i] = list(filter(lambda x: x!= -100, predictions[i]))\n",
        "\n",
        "        # remove os pad_tokens\n",
        "        labels[i] = list(filter(lambda x: x!= tokenizer.pad_token_id, labels[i]))\n",
        "        predictions[i] = list(filter(lambda x: x!= tokenizer.pad_token_id, predictions[i]))\n",
        "\n",
        "        # remove os eos_tokens\n",
        "        labels[i] = list(filter(lambda x: x!= tokenizer.eos_token_id, labels[i]))\n",
        "        predictions[i] = list(filter(lambda x: x!= tokenizer.eos_token_id, predictions[i]))\n",
        "\n",
        "\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    # print('Decoded labels')\n",
        "    # print(decoded_labels)\n",
        "    # print('Decoded predictions')\n",
        "    # print(decoded_preds)\n",
        "\n",
        "    result = mrpc_metric(decoded_preds,decoded_labels)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "f_gQBsMUkHKn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função métrica para encoders\n",
        "\n",
        "Para encoders, a funçao da métrica é mais simples."
      ],
      "metadata": {
        "id": "QrKkHZY0BHF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from evaluate import load\n",
        "\n",
        "if model_type=='encoder':\n",
        "    def compute_metrics(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "        acc_metric = load(\"accuracy\")\n",
        "        result = acc_metric.compute(predictions=predictions,references=labels)\n",
        "        return {'mrpc_acc': result['accuracy']}"
      ],
      "metadata": {
        "id": "Wacq2Z1iBI-b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataCollator para Encoder-Decoder (Causal Language Modeling)\n",
        "\n",
        "A única modificação feita do código original é silenciar o tokenizador durante o pad\n",
        "https://github.com/huggingface/transformers/blob/v4.28.1/src/transformers/data/data_collator.py"
      ],
      "metadata": {
        "id": "eNpMe-oOy0GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import warnings\n",
        "from collections.abc import Mapping\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
        "\n",
        "from transformers.models.bert import BertTokenizer, BertTokenizerFast\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
        "from transformers.utils import PaddingStrategy\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForSeq2SeqModified:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs received, as well as the labels.\n",
        "    Args:\n",
        "        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
        "            The tokenizer used for encoding the data.\n",
        "        model ([`PreTrainedModel`]):\n",
        "            The model that is being trained. If set and has the *prepare_decoder_input_ids_from_labels*, use it to\n",
        "            prepare the *decoder_input_ids*\n",
        "            This is useful when using *label_smoothing* to avoid calculating loss twice.\n",
        "        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
        "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
        "            among:\n",
        "            - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n",
        "              sequence is provided).\n",
        "            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
        "              acceptable input length for the model if that argument is not provided.\n",
        "            - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n",
        "        max_length (`int`, *optional*):\n",
        "            Maximum length of the returned list and optionally padding length (see above).\n",
        "        pad_to_multiple_of (`int`, *optional*):\n",
        "            If set will pad the sequence to a multiple of the provided value.\n",
        "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
        "            7.5 (Volta).\n",
        "        label_pad_token_id (`int`, *optional*, defaults to -100):\n",
        "            The id to use when padding the labels (-100 will be automatically ignored by PyTorch loss functions).\n",
        "        return_tensors (`str`):\n",
        "            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    model: Optional[Any] = None\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "    label_pad_token_id: int = -100\n",
        "    return_tensors: str = \"pt\"\n",
        "\n",
        "    def __call__(self, features, return_tensors=None):\n",
        "        if return_tensors is None:\n",
        "            return_tensors = self.return_tensors\n",
        "        labels = [feature[\"labels\"] for feature in features] if \"labels\" in features[0].keys() else None\n",
        "\n",
        "        previous_level = transformers.logging.get_verbosity()\n",
        "        transformers.logging.set_verbosity_error()\n",
        "\n",
        "        # We have to pad the labels before calling `tokenizer.pad` as this method won't pad them and needs them of the\n",
        "        # same length to return tensors.\n",
        "        if labels is not None:\n",
        "            max_label_length = max(len(l) for l in labels)\n",
        "            if self.pad_to_multiple_of is not None:\n",
        "                max_label_length = (\n",
        "                    (max_label_length + self.pad_to_multiple_of - 1)\n",
        "                    // self.pad_to_multiple_of\n",
        "                    * self.pad_to_multiple_of\n",
        "                )\n",
        "\n",
        "            padding_side = self.tokenizer.padding_side\n",
        "            for feature in features:\n",
        "                remainder = [self.label_pad_token_id] * (max_label_length - len(feature[\"labels\"]))\n",
        "                if isinstance(feature[\"labels\"], list):\n",
        "                    feature[\"labels\"] = (\n",
        "                        feature[\"labels\"] + remainder if padding_side == \"right\" else remainder + feature[\"labels\"]\n",
        "                    )\n",
        "                elif padding_side == \"right\":\n",
        "                    feature[\"labels\"] = np.concatenate([feature[\"labels\"], remainder]).astype(np.int64)\n",
        "                else:\n",
        "                    feature[\"labels\"] = np.concatenate([remainder, feature[\"labels\"]]).astype(np.int64)\n",
        "\n",
        "        features = self.tokenizer.pad(\n",
        "            features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=return_tensors,\n",
        "        )\n",
        "\n",
        "\n",
        "        # prepare decoder_input_ids\n",
        "        if (\n",
        "            labels is not None\n",
        "            and self.model is not None\n",
        "            and hasattr(self.model, \"prepare_decoder_input_ids_from_labels\")\n",
        "        ):\n",
        "            decoder_input_ids = self.model.prepare_decoder_input_ids_from_labels(labels=features[\"labels\"])\n",
        "            features[\"decoder_input_ids\"] = decoder_input_ids\n",
        "\n",
        "        transformers.logging.set_verbosity(previous_level) ####\n",
        "        return features"
      ],
      "metadata": {
        "id": "S222oaA0y0OO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmOgli9IKGE7"
      },
      "source": [
        "# DataCollator para Decoders (Causal Language Modeling)\n",
        "\n",
        "Enquanto os modelos encoder-decoder possuem o input e os outputs separados, nos modelos decoder, só há um vetor de texto.\n",
        "\n",
        "No finetunning para classificação dos modelos decoders, colocaremos para o modelo apenas prever o texto do label. Então será atribuído à parte do input um label de valor -100, assim o modelo saberá que não deve ser calculado *loss* para esses tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JqCUqkohKLnH"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import warnings\n",
        "from collections.abc import Mapping\n",
        "from dataclasses import dataclass\n",
        "from random import randint\n",
        "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from transformers.models.bert import BertTokenizer, BertTokenizerFast\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
        "from transformers.utils import PaddingStrategy\n",
        "\n",
        "import torch\n",
        "import transformers.data.data_collator\n",
        "from transformers.data.data_collator import _torch_collate_batch\n",
        "\n",
        "\n",
        "class DataCollatorMixin:\n",
        "    def __call__(self, features, return_tensors=None):\n",
        "        if return_tensors is None:\n",
        "            return_tensors = self.return_tensors\n",
        "        if return_tensors == \"tf\":\n",
        "            return self.tf_call(features)\n",
        "        elif return_tensors == \"pt\":\n",
        "            return self.torch_call(features)\n",
        "        elif return_tensors == \"np\":\n",
        "            return self.numpy_call(features)\n",
        "        else:\n",
        "            raise ValueError(f\"Framework '{return_tensors}' not recognized!\")\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorWithPaddingModified:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs received.\n",
        "    Args:\n",
        "        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
        "            The tokenizer used for encoding the data.\n",
        "        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
        "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
        "            among:\n",
        "            - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n",
        "              sequence is provided).\n",
        "            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
        "              acceptable input length for the model if that argument is not provided.\n",
        "            - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n",
        "        max_length (`int`, *optional*):\n",
        "            Maximum length of the returned list and optionally padding length (see above).\n",
        "        pad_to_multiple_of (`int`, *optional*):\n",
        "            If set will pad the sequence to a multiple of the provided value.\n",
        "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
        "            7.5 (Volta).\n",
        "        return_tensors (`str`):\n",
        "            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "    return_tensors: str = \"pt\"\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        inputs=[]\n",
        "        labels=[]\n",
        "        attention_mask=[]\n",
        "\n",
        "        is_validation_dataset = (features[0]['labels'][0] > len(tokenizer))\n",
        "        if is_validation_dataset:\n",
        "            i = 0\n",
        "            for feat in features:\n",
        "                labels.append(feat['labels'][1:])\n",
        "                inputs.append(feat['input_ids'])\n",
        "        else: # training datset\n",
        "            for feat in features:\n",
        "                labels.append([-100] * len(feat['input_ids']) + feat['labels'])\n",
        "                inputs.append(feat['input_ids'] + feat['labels'])\n",
        "\n",
        "        # artifício para dar pad nos inputs e labels ao mesmo tempo\n",
        "        inputs = {'input_ids' : inputs + labels}\n",
        "\n",
        "        previous_level = transformers.logging.get_verbosity()\n",
        "        transformers.logging.set_verbosity_error()\n",
        "        #####\n",
        "        batch = self.tokenizer.pad(\n",
        "            inputs,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=self.return_tensors,\n",
        "        )\n",
        "        transformers.logging.set_verbosity(previous_level) ####\n",
        "\n",
        "        half_idx = len(labels)\n",
        "\n",
        "        batch['labels'] = batch['input_ids'][half_idx:len(batch['input_ids'])]\n",
        "        batch['input_ids'] = batch['input_ids'][0:half_idx]\n",
        "        batch['attention_mask'] = batch['attention_mask'][0:half_idx]\n",
        "\n",
        "\n",
        "        batch['labels'][batch['labels'] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        if \"label\" in batch:\n",
        "            batch[\"labels\"] = batch[\"label\"]\n",
        "            del batch[\"label\"]\n",
        "        if \"label_ids\" in batch:\n",
        "            batch[\"labels\"] = batch[\"label_ids\"]\n",
        "            del batch[\"label_ids\"]\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPYv_RDwUN91"
      },
      "source": [
        "# Treina o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdyvQDUPiBFw"
      },
      "source": [
        "## Ajusta a classe Trainer do hugginface\n",
        "\n",
        "Foi alterada na classe Trainer a configuração de geração de textos de validação e silenciado os avisos na geração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "waZy7Ee_0jvY"
      },
      "outputs": [],
      "source": [
        "# https://github.com/huggingface/transformers/blob/v4.26.1/src/transformers/trainer_seq2seq.py\n",
        "# Copyright 2020 The HuggingFace Team. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "from typing import Any, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from transformers.deepspeed import is_deepspeed_zero3_enabled\n",
        "from transformers.trainer import Trainer\n",
        "from transformers.trainer_utils import PredictionOutput\n",
        "from transformers.utils import logging\n",
        "import transformers\n",
        "\n",
        "\n",
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "class Seq2SeqTrainerModified(Trainer):\n",
        "    def evaluate(\n",
        "        self,\n",
        "        eval_dataset: Optional[Dataset] = None,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "        metric_key_prefix: str = \"eval\",\n",
        "        **gen_kwargs\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Run evaluation and returns metrics.\n",
        "        The calling script will be responsible for providing a method to compute metrics, as they are task-dependent\n",
        "        (pass it to the init `compute_metrics` argument).\n",
        "        You can also subclass and override this method to inject custom behavior.\n",
        "        Args:\n",
        "            eval_dataset (`Dataset`, *optional*):\n",
        "                Pass a dataset if you wish to override `self.eval_dataset`. If it is an [`~datasets.Dataset`], columns\n",
        "                not accepted by the `model.forward()` method are automatically removed. It must implement the `__len__`\n",
        "                method.\n",
        "            ignore_keys (`List[str]`, *optional*):\n",
        "                A list of keys in the output of your model (if it is a dictionary) that should be ignored when\n",
        "                gathering predictions.\n",
        "            metric_key_prefix (`str`, *optional*, defaults to `\"eval\"`):\n",
        "                An optional prefix to be used as the metrics key prefix. For example the metrics \"bleu\" will be named\n",
        "                \"eval_bleu\" if the prefix is `\"eval\"` (default)\n",
        "            max_length (`int`, *optional*):\n",
        "                The maximum target length to use when predicting with the generate method.\n",
        "            num_beams (`int`, *optional*):\n",
        "                Number of beams for beam search that will be used when predicting with the generate method. 1 means no\n",
        "                beam search.\n",
        "            gen_kwargs:\n",
        "                Additional `generate` specific kwargs.\n",
        "        Returns:\n",
        "            A dictionary containing the evaluation loss and the potential metrics computed from the predictions. The\n",
        "            dictionary also contains the epoch number which comes from the training state.\n",
        "        \"\"\"\n",
        "\n",
        "        gen_kwargs = gen_kwargs.copy()\n",
        "        if gen_kwargs.get(\"max_length\") is None and gen_kwargs.get(\"max_new_tokens\") is None:\n",
        "            gen_kwargs[\"max_length\"] = self.args.generation_max_length\n",
        "        gen_kwargs[\"num_beams\"] = (\n",
        "            gen_kwargs[\"num_beams\"] if gen_kwargs.get(\"num_beams\") is not None else self.args.generation_num_beams\n",
        "        )\n",
        "        self._gen_kwargs = gen_kwargs\n",
        "\n",
        "        return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
        "\n",
        "    def predict(\n",
        "        self,\n",
        "        test_dataset: Dataset,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "        metric_key_prefix: str = \"test\",\n",
        "        **gen_kwargs\n",
        "    ) -> PredictionOutput:\n",
        "        \"\"\"\n",
        "        Run prediction and returns predictions and potential metrics.\n",
        "        Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method\n",
        "        will also return metrics, like in `evaluate()`.\n",
        "        Args:\n",
        "            test_dataset (`Dataset`):\n",
        "                Dataset to run the predictions on. If it is a [`~datasets.Dataset`], columns not accepted by the\n",
        "                `model.forward()` method are automatically removed. Has to implement the method `__len__`\n",
        "            ignore_keys (`List[str]`, *optional*):\n",
        "                A list of keys in the output of your model (if it is a dictionary) that should be ignored when\n",
        "                gathering predictions.\n",
        "            metric_key_prefix (`str`, *optional*, defaults to `\"eval\"`):\n",
        "                An optional prefix to be used as the metrics key prefix. For example the metrics \"bleu\" will be named\n",
        "                \"eval_bleu\" if the prefix is `\"eval\"` (default)\n",
        "            max_length (`int`, *optional*):\n",
        "                The maximum target length to use when predicting with the generate method.\n",
        "            num_beams (`int`, *optional*):\n",
        "                Number of beams for beam search that will be used when predicting with the generate method. 1 means no\n",
        "                beam search.\n",
        "            gen_kwargs:\n",
        "                Additional `generate` specific kwargs.\n",
        "        <Tip>\n",
        "        If your predictions or labels have different sequence lengths (for instance because you're doing dynamic\n",
        "        padding in a token classification task) the predictions will be padded (on the right) to allow for\n",
        "        concatenation into one array. The padding index is -100.\n",
        "        </Tip>\n",
        "        Returns: *NamedTuple* A namedtuple with the following keys:\n",
        "            - predictions (`np.ndarray`): The predictions on `test_dataset`.\n",
        "            - label_ids (`np.ndarray`, *optional*): The labels (if the dataset contained some).\n",
        "            - metrics (`Dict[str, float]`, *optional*): The potential dictionary of metrics (if the dataset contained\n",
        "              labels).\n",
        "        \"\"\"\n",
        "\n",
        "        gen_kwargs = gen_kwargs.copy()\n",
        "        if gen_kwargs.get(\"max_length\") is None and gen_kwargs.get(\"max_new_tokens\") is None:\n",
        "            gen_kwargs[\"max_length\"] = self.args.generation_max_length\n",
        "        gen_kwargs[\"num_beams\"] = (\n",
        "            gen_kwargs[\"num_beams\"] if gen_kwargs.get(\"num_beams\") is not None else self.args.generation_num_beams\n",
        "        )\n",
        "        self._gen_kwargs = gen_kwargs\n",
        "\n",
        "        return super().predict(test_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
        "\n",
        "    def prediction_step(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        inputs: Dict[str, Union[torch.Tensor, Any]],\n",
        "        prediction_loss_only: bool,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "    ) -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Perform an evaluation step on `model` using `inputs`.\n",
        "        Subclass and override to inject custom behavior.\n",
        "        Args:\n",
        "            model (`nn.Module`):\n",
        "                The model to evaluate.\n",
        "            inputs (`Dict[str, Union[torch.Tensor, Any]]`):\n",
        "                The inputs and targets of the model.\n",
        "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
        "                argument `labels`. Check your model's documentation for all accepted arguments.\n",
        "            prediction_loss_only (`bool`):\n",
        "                Whether or not to return the loss only.\n",
        "        Return:\n",
        "            Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]: A tuple with the loss, logits and\n",
        "            labels (each being optional).\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.args.predict_with_generate or prediction_loss_only:\n",
        "            return super().prediction_step(\n",
        "                model, inputs, prediction_loss_only=prediction_loss_only, ignore_keys=ignore_keys\n",
        "            )\n",
        "\n",
        "        has_labels = \"labels\" in inputs\n",
        "        inputs = self._prepare_inputs(inputs)\n",
        "\n",
        "        # XXX: adapt synced_gpus for fairscale as well\n",
        "        gen_kwargs = self._gen_kwargs.copy()\n",
        "        if gen_kwargs.get(\"max_length\") is None and gen_kwargs.get(\"max_new_tokens\") is None:\n",
        "            gen_kwargs[\"max_length\"] = self.model.config.max_length\n",
        "        gen_kwargs[\"num_beams\"] = (\n",
        "            gen_kwargs[\"num_beams\"] if gen_kwargs.get(\"num_beams\") is not None else self.model.config.num_beams\n",
        "        )\n",
        "        default_synced_gpus = True if is_deepspeed_zero3_enabled() else False\n",
        "        gen_kwargs[\"synced_gpus\"] = (\n",
        "            gen_kwargs[\"synced_gpus\"] if gen_kwargs.get(\"synced_gpus\") is not None else default_synced_gpus\n",
        "        )\n",
        "\n",
        "        if \"attention_mask\" in inputs:\n",
        "            gen_kwargs[\"attention_mask\"] = inputs.get(\"attention_mask\", None)\n",
        "        if \"global_attention_mask\" in inputs:\n",
        "            gen_kwargs[\"global_attention_mask\"] = inputs.get(\"global_attention_mask\", None)\n",
        "\n",
        "        # prepare generation inputs\n",
        "        # some encoder-decoder models can have varying encoder's and thus\n",
        "        # varying model input names\n",
        "        if hasattr(self.model, \"encoder\") and self.model.encoder.main_input_name != self.model.main_input_name:\n",
        "            generation_inputs = inputs[self.model.encoder.main_input_name]\n",
        "        else:\n",
        "            generation_inputs = inputs[self.model.main_input_name]\n",
        "\n",
        "        ##### Alteração\n",
        "        gen_kwargs[\"max_new_tokens\"] = MAX_TOKEN_GENERATION_LENGTH\n",
        "        del gen_kwargs[\"max_length\"]\n",
        "        gen_kwargs[\"eos_token_id\"]=self.tokenizer.eos_token_id\n",
        "        previous_level = transformers.logging.get_verbosity()\n",
        "        transformers.logging.set_verbosity_error()\n",
        "        #####\n",
        "        generated_tokens = self.model.generate(\n",
        "            generation_inputs,\n",
        "            **gen_kwargs\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        # in case the batch is shorter than max length, the output should be padded\n",
        "        if gen_kwargs.get(\"max_length\") is not None and generated_tokens.shape[-1] < gen_kwargs[\"max_length\"]:\n",
        "            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_length\"])\n",
        "        elif gen_kwargs.get(\"max_new_tokens\") is not None and generated_tokens.shape[-1] < (\n",
        "            gen_kwargs[\"max_new_tokens\"] + 1\n",
        "        ):\n",
        "            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_new_tokens\"] + 1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if has_labels:\n",
        "                with self.compute_loss_context_manager():\n",
        "                    outputs = model(**inputs)\n",
        "                if self.label_smoother is not None:\n",
        "                    loss = self.label_smoother(outputs, inputs[\"labels\"]).mean().detach()\n",
        "                else:\n",
        "                    loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
        "            else:\n",
        "                loss = None\n",
        "\n",
        "        if self.args.prediction_loss_only:\n",
        "            return (loss, None, None)\n",
        "\n",
        "        if has_labels:\n",
        "            labels = inputs[\"labels\"]\n",
        "            if gen_kwargs.get(\"max_length\") is not None and labels.shape[-1] < gen_kwargs[\"max_length\"]:\n",
        "                labels = self._pad_tensors_to_max_len(labels, gen_kwargs[\"max_length\"])\n",
        "            elif gen_kwargs.get(\"max_new_tokens\") is not None and labels.shape[-1] < (\n",
        "                gen_kwargs[\"max_new_tokens\"] + 1\n",
        "            ):\n",
        "                labels = self._pad_tensors_to_max_len(labels, (gen_kwargs[\"max_new_tokens\"] + 1))\n",
        "        else:\n",
        "            labels = None\n",
        "        transformers.logging.set_verbosity(previous_level) ####\n",
        "        return (loss, generated_tokens, labels)\n",
        "\n",
        "    def _pad_tensors_to_max_len(self, tensor, max_length):\n",
        "        if self.tokenizer is not None and hasattr(self.tokenizer, \"pad_token_id\"):\n",
        "            # If PAD token is not defined at least EOS token has to be defined\n",
        "            pad_token_id = (\n",
        "                self.tokenizer.pad_token_id if self.tokenizer.pad_token_id is not None else self.tokenizer.eos_token_id\n",
        "            )\n",
        "        else:\n",
        "            if self.model.config.pad_token_id is not None:\n",
        "                pad_token_id = self.model.config.pad_token_id\n",
        "            else:\n",
        "                raise ValueError(\"Pad_token_id must be set in the configuration of the model, in order to pad tensors\")\n",
        "\n",
        "        padded_tensor = pad_token_id * torch.ones(\n",
        "            (tensor.shape[0], max_length), dtype=tensor.dtype, device=tensor.device\n",
        "        )\n",
        "        padded_tensor[:, : tensor.shape[-1]] = tensor\n",
        "        return padded_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jgrlcn-C_Gs"
      },
      "source": [
        "## Treina o model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treino"
      ],
      "metadata": {
        "id": "MdWH5_LQht_n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AcBhmIJBory",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5ed3c32296d149b6be9eb2879d48b0e1",
            "e3f212d459ec4335965c7df8321438d1",
            "4f2a54d4ce9a41ecb38cde2724e6b798",
            "c9e01aeed39c4f0da94a8aeab08638db",
            "3e0b0af4ad804600ac504d9a16570769",
            "c102d619c38644f68989dcd07eda4cc3",
            "fa95880d38e54081836e13c32b3cbb2a",
            "48fc9092797046b980f4fb8961e2891f",
            "6e3e739bda134f67954ffaeeac8305f4",
            "8d356ab7f2894329b37f2e79cc60d73d",
            "9da8f4e523a7452994ccef93f34dd59e"
          ]
        },
        "outputId": "2099f751-e0bf-4a26-ac4b-d4fdc176a73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 15:33, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Mrpc Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.647900</td>\n",
              "      <td>0.598592</td>\n",
              "      <td>0.682171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.514500</td>\n",
              "      <td>0.373698</td>\n",
              "      <td>0.850129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.347400</td>\n",
              "      <td>0.314132</td>\n",
              "      <td>0.863049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.216600</td>\n",
              "      <td>0.306313</td>\n",
              "      <td>0.878553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.157100</td>\n",
              "      <td>0.323758</td>\n",
              "      <td>0.883721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.090700</td>\n",
              "      <td>0.372456</td>\n",
              "      <td>0.901809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.062000</td>\n",
              "      <td>0.448410</td>\n",
              "      <td>0.883721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.042700</td>\n",
              "      <td>0.432733</td>\n",
              "      <td>0.881137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.447747</td>\n",
              "      <td>0.886305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.020500</td>\n",
              "      <td>0.441889</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ed3c32296d149b6be9eb2879d48b0e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorWithPadding\n",
        "import torch\n",
        "import os\n",
        "\n",
        "\n",
        "if model_type=='decoder':\n",
        "    data_collator = DataCollatorWithPaddingModified(tokenizer,max_length=model.config.n_positions,pad_to_multiple_of=8,return_tensors='pt')\n",
        "    compute_metrics=compute_metrics\n",
        "    learning_rate=1e-4\n",
        "    predict_with_generate=True\n",
        "elif model_type=='encoder-decoder':\n",
        "    data_collator = DataCollatorForSeq2SeqModified(tokenizer,model=model,max_length=context_length,pad_to_multiple_of=8,return_tensors='pt')\n",
        "    compute_metrics=compute_metrics\n",
        "    learning_rate=1e-4\n",
        "    predict_with_generate=True\n",
        "elif model_type=='encoder':\n",
        "    data_collator = DataCollatorWithPadding(tokenizer,max_length=context_length,pad_to_multiple_of=8,return_tensors='pt')\n",
        "    compute_metrics=compute_metrics\n",
        "    learning_rate=5e-5\n",
        "    predict_with_generate=False\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,\n",
        "\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    eval_steps=1,\n",
        "\n",
        "    logging_strategy=\"epoch\",\n",
        "    logging_steps=1,\n",
        "    predict_with_generate=predict_with_generate,\n",
        "    # resume_from_checkpoint=RESUME_FROM_CHECKPOINT,\n",
        "\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,\n",
        "\n",
        "    num_train_epochs=epochs,\n",
        "\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_ratio=0.1, # warmup de 10% do treino\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=0.1,\n",
        "\n",
        "    fp16=fp16,\n",
        "    fp16_full_eval=fp16,\n",
        "    dataloader_num_workers=1,\n",
        "    # push_to_hub=True,\n",
        "    # hub_token='token_do_huggingface',\n",
        "    # hub_strategy=\"checkpoint\",\n",
        "    # hub_model_id=\"nome_do_usuario/nome_do_mudelo\",\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainerModified(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=ds_tokenizado[\"train\"],\n",
        "    eval_dataset=ds_tokenizado[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train(resume_from_checkpoint=RESUME_FROM_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOSO48cz5XJG"
      },
      "source": [
        "# Gera texto pelo modelo finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKf0PGC-BFWm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "if model_type!='encoder':\n",
        "    texts=[]\n",
        "\n",
        "    for key in ds_processado.keys():\n",
        "        texts.append(ds_processado[key][0]['text'])\n",
        "        texts.append(ds_processado[key][1]['text'])\n",
        "    model.to('cpu')\n",
        "    pred=[]\n",
        "\n",
        "    previous_level = transformers.logging.get_verbosity()\n",
        "    transformers.logging.set_verbosity_error()\n",
        "\n",
        "    for text in texts:\n",
        "        pred.append(tokenizer.batch_decode(model.generate(tokenizer.encode(text,return_tensors='pt'),max_new_tokens=20,eos_token_id=tokenizer.eos_token_id)))\n",
        "\n",
        "    transformers.logging.set_verbosity(previous_level) ####\n",
        "\n",
        "    for i in range(0,len(texts)):\n",
        "        print('input:',texts[i])\n",
        "        print('generated:',pred[i])\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrOh9N02Su-_"
      },
      "source": [
        "# Desconectar do COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbosINFq2VhP"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d521787d1cc342d9b38a9088144f6e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9c976e229d2482da023213957890c3b",
              "IPY_MODEL_96dfd03ca67d478b9475ac46e351b0d0",
              "IPY_MODEL_223f037d73574effa62a7e7b1e1ccc09"
            ],
            "layout": "IPY_MODEL_1371b50a2c414236abd3d2187d9b6efe"
          }
        },
        "e9c976e229d2482da023213957890c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15ab93fdfd4c4a90917c321a922189a6",
            "placeholder": "​",
            "style": "IPY_MODEL_a95640943d224bbabbb46d6207001989",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "96dfd03ca67d478b9475ac46e351b0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5276abf563064206ac6d271039a66186",
            "max": 51,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88a41276cd554ade940d5fd7c214a9d9",
            "value": 51
          }
        },
        "223f037d73574effa62a7e7b1e1ccc09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d28834f480054ede9e9af1d6c00fb091",
            "placeholder": "​",
            "style": "IPY_MODEL_96af53daf9944aa887b8b9b086fe0903",
            "value": " 51.0/51.0 [00:00&lt;00:00, 2.28kB/s]"
          }
        },
        "1371b50a2c414236abd3d2187d9b6efe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15ab93fdfd4c4a90917c321a922189a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95640943d224bbabbb46d6207001989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5276abf563064206ac6d271039a66186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88a41276cd554ade940d5fd7c214a9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d28834f480054ede9e9af1d6c00fb091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96af53daf9944aa887b8b9b086fe0903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "495c3b439bfd414a8b6bb6b66f6a6547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11b530516bbc4684bf711642606ee620",
              "IPY_MODEL_2fa2a160e15e4e55a311aec16db0cf78",
              "IPY_MODEL_2f814f0fc0e9454691abe4ac7557cf88"
            ],
            "layout": "IPY_MODEL_d982aa17b8354b7385e9138953645be3"
          }
        },
        "11b530516bbc4684bf711642606ee620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b6ea72cd8694771ba2684db6886f8a6",
            "placeholder": "​",
            "style": "IPY_MODEL_71830082d1c148a799eab8c645a1d9ac",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "2fa2a160e15e4e55a311aec16db0cf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa6d92fe21f44feb1cadcfc8d857dc5",
            "max": 606,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db99058a1e02433fa0eb0845e96cdaa1",
            "value": 606
          }
        },
        "2f814f0fc0e9454691abe4ac7557cf88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4feea995684344838011dcd2d0541e4d",
            "placeholder": "​",
            "style": "IPY_MODEL_8c473e4bfc54466d85cb3db2e4d90373",
            "value": " 606/606 [00:00&lt;00:00, 34.4kB/s]"
          }
        },
        "d982aa17b8354b7385e9138953645be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b6ea72cd8694771ba2684db6886f8a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71830082d1c148a799eab8c645a1d9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfa6d92fe21f44feb1cadcfc8d857dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db99058a1e02433fa0eb0845e96cdaa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4feea995684344838011dcd2d0541e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c473e4bfc54466d85cb3db2e4d90373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d2348bfdfef4db58e3226340bcdeb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0d3960d491b4ce598d267dc1b31d290",
              "IPY_MODEL_3761085aabf34491a490b78d52733084",
              "IPY_MODEL_64451c7168354169aa1149973bb03c5f"
            ],
            "layout": "IPY_MODEL_1ef721cfd50a4f3a994bf5dfc15b4396"
          }
        },
        "f0d3960d491b4ce598d267dc1b31d290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f61735352c2d45f6a0bfe6d50dc63084",
            "placeholder": "​",
            "style": "IPY_MODEL_10afd0c1940f447cb044552515ca4b0c",
            "value": "Downloading spm.model: 100%"
          }
        },
        "3761085aabf34491a490b78d52733084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80ab21a5c7074c67a268852f39a17611",
            "max": 815684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_490a76ab50fc4e34a3c878cafa12d5f7",
            "value": 815684
          }
        },
        "64451c7168354169aa1149973bb03c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89df2bf82207486d859e8f3bfc52dce1",
            "placeholder": "​",
            "style": "IPY_MODEL_2e0f9c0eabd949db91117c2f8b269050",
            "value": " 816k/816k [00:00&lt;00:00, 8.54MB/s]"
          }
        },
        "1ef721cfd50a4f3a994bf5dfc15b4396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61735352c2d45f6a0bfe6d50dc63084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10afd0c1940f447cb044552515ca4b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80ab21a5c7074c67a268852f39a17611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "490a76ab50fc4e34a3c878cafa12d5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89df2bf82207486d859e8f3bfc52dce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e0f9c0eabd949db91117c2f8b269050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b051fae17374d72bb88de17e8a4cc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76c4acb24c0e4862bfe2ef30c7e49c47",
              "IPY_MODEL_70e345cc035248269cbf8d2e1a25097e",
              "IPY_MODEL_6b6a97fb6f75494fab5956cc44d7e4f7"
            ],
            "layout": "IPY_MODEL_298340109012411c8aa9caafa3acd10c"
          }
        },
        "76c4acb24c0e4862bfe2ef30c7e49c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f86fd4880384495b0756a39af14822f",
            "placeholder": "​",
            "style": "IPY_MODEL_ac0b1f55aa62407eb57c4c944720b4be",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "70e345cc035248269cbf8d2e1a25097e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ced7fd6afdc4dcdb4ba080fae20da85",
            "max": 271997445,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4f5dcb6a3224f4f91922b26f0c29662",
            "value": 271997445
          }
        },
        "6b6a97fb6f75494fab5956cc44d7e4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da604443eb85406e973877926abd2920",
            "placeholder": "​",
            "style": "IPY_MODEL_f1ea91c9d09d4e02957d2a971049f441",
            "value": " 272M/272M [00:01&lt;00:00, 141MB/s]"
          }
        },
        "298340109012411c8aa9caafa3acd10c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f86fd4880384495b0756a39af14822f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0b1f55aa62407eb57c4c944720b4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ced7fd6afdc4dcdb4ba080fae20da85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4f5dcb6a3224f4f91922b26f0c29662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da604443eb85406e973877926abd2920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ea91c9d09d4e02957d2a971049f441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cb62eb9b552489ab9d3986e9abe7e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_528b822601c64647a4c659ac04dda0c2",
              "IPY_MODEL_2d04369bacad446e839ccc60dc5b55a2",
              "IPY_MODEL_4f26dfe0c6e249ca87394776d9a9a5ce"
            ],
            "layout": "IPY_MODEL_242c8d799ffc4274b3ab9f5bcff91077"
          }
        },
        "528b822601c64647a4c659ac04dda0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9240628e60cf4a3c831a9432342e845e",
            "placeholder": "​",
            "style": "IPY_MODEL_943ffe94b09642fda92b5736671297c9",
            "value": "Map (num_proc=2):  50%"
          }
        },
        "2d04369bacad446e839ccc60dc5b55a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f93f0b059ff4020aed24ac93484864c",
            "max": 3549,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0ee6ebd49cb46e9aa06f48657155df1",
            "value": 3549
          }
        },
        "4f26dfe0c6e249ca87394776d9a9a5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e4150f4d05b416fab0cd72790ff0feb",
            "placeholder": "​",
            "style": "IPY_MODEL_e3d43acde3c1493fbd7c743b2e2c8a53",
            "value": " 1774/3549 [00:00&lt;00:00, 8698.79 examples/s]"
          }
        },
        "242c8d799ffc4274b3ab9f5bcff91077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "9240628e60cf4a3c831a9432342e845e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "943ffe94b09642fda92b5736671297c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f93f0b059ff4020aed24ac93484864c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0ee6ebd49cb46e9aa06f48657155df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e4150f4d05b416fab0cd72790ff0feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d43acde3c1493fbd7c743b2e2c8a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92b240804fbc4e2cae71d458a6efd94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41789bbffa94461ea116d9a69dc38d48",
              "IPY_MODEL_93fcd9dacc534c65899073f627cb6874",
              "IPY_MODEL_a2e066e4f24247338d4aff20cab2388b"
            ],
            "layout": "IPY_MODEL_1397dcfb9ffc4edaa58e8a8234133941"
          }
        },
        "41789bbffa94461ea116d9a69dc38d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_903ca7610b864932bb972d816407a693",
            "placeholder": "​",
            "style": "IPY_MODEL_2a67508a15534e2e86f7e70c6a4f221a",
            "value": "Map (num_proc=2):  50%"
          }
        },
        "93fcd9dacc534c65899073f627cb6874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2cf92ae5ccd469d96e05ab68d4a113d",
            "max": 388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e873026dd3049938df61fef2c298751",
            "value": 388
          }
        },
        "a2e066e4f24247338d4aff20cab2388b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c569737a7e04323ae399f33941558ca",
            "placeholder": "​",
            "style": "IPY_MODEL_40e0e72a06674e94af182d451a8eb1ca",
            "value": " 194/388 [00:00&lt;00:00, 1229.05 examples/s]"
          }
        },
        "1397dcfb9ffc4edaa58e8a8234133941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "903ca7610b864932bb972d816407a693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a67508a15534e2e86f7e70c6a4f221a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2cf92ae5ccd469d96e05ab68d4a113d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e873026dd3049938df61fef2c298751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c569737a7e04323ae399f33941558ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e0e72a06674e94af182d451a8eb1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c8b712dc7d04eaaafae8a2be162d226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8002379101d24dc39ea6c2ecac437107",
              "IPY_MODEL_5c425aa7686a476295517ba02f21710a",
              "IPY_MODEL_5cb9efe1e8124eb4a1f3e2f9100c2f49"
            ],
            "layout": "IPY_MODEL_2778eef18f314bcd98af15f0b6daaa23"
          }
        },
        "8002379101d24dc39ea6c2ecac437107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a058b843ad4c399db57a4d2b198dc1",
            "placeholder": "​",
            "style": "IPY_MODEL_72853bc8f687494bb6ffc9d2096f49da",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "5c425aa7686a476295517ba02f21710a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ebaa628d439466dbaf0b7270f2ba744",
            "max": 3532,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d8ebe3211ee43c29283a9390d1b7e6e",
            "value": 3532
          }
        },
        "5cb9efe1e8124eb4a1f3e2f9100c2f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e01c202baee46378411926181bd20a0",
            "placeholder": "​",
            "style": "IPY_MODEL_425d3fceb2d74789bf5f956a79c48cb6",
            "value": " 3532/3532 [00:01&lt;00:00, 3348.03 examples/s]"
          }
        },
        "2778eef18f314bcd98af15f0b6daaa23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d4a058b843ad4c399db57a4d2b198dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72853bc8f687494bb6ffc9d2096f49da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ebaa628d439466dbaf0b7270f2ba744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d8ebe3211ee43c29283a9390d1b7e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e01c202baee46378411926181bd20a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "425d3fceb2d74789bf5f956a79c48cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c759a27928ac4a48a2a2afdd16379f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02955cadce084c88bdb82a6592ff12f4",
              "IPY_MODEL_04cdd2b5f4a8433bb4d660fdb01a133d",
              "IPY_MODEL_6a0bf3abb249427188ebdaad3e86fe2d"
            ],
            "layout": "IPY_MODEL_133e4a50a5e3437aada09ae5aa203fd8"
          }
        },
        "02955cadce084c88bdb82a6592ff12f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_735b34ecc0a64283a746b59f63d9f3b7",
            "placeholder": "​",
            "style": "IPY_MODEL_96683dfbc1854c11b04dc343709ab79a",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "04cdd2b5f4a8433bb4d660fdb01a133d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a896b145d75f4a62b47f48beb0428c6a",
            "max": 387,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8096558a955747cabb23abf134936213",
            "value": 387
          }
        },
        "6a0bf3abb249427188ebdaad3e86fe2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a28bb11984c4240a38dbb89945de979",
            "placeholder": "​",
            "style": "IPY_MODEL_af7df589528b4ab89e0adeca0ad18db1",
            "value": " 387/387 [00:00&lt;00:00, 779.60 examples/s]"
          }
        },
        "133e4a50a5e3437aada09ae5aa203fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "735b34ecc0a64283a746b59f63d9f3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96683dfbc1854c11b04dc343709ab79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a896b145d75f4a62b47f48beb0428c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8096558a955747cabb23abf134936213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a28bb11984c4240a38dbb89945de979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af7df589528b4ab89e0adeca0ad18db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ed3c32296d149b6be9eb2879d48b0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3f212d459ec4335965c7df8321438d1",
              "IPY_MODEL_4f2a54d4ce9a41ecb38cde2724e6b798",
              "IPY_MODEL_c9e01aeed39c4f0da94a8aeab08638db"
            ],
            "layout": "IPY_MODEL_3e0b0af4ad804600ac504d9a16570769"
          }
        },
        "e3f212d459ec4335965c7df8321438d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c102d619c38644f68989dcd07eda4cc3",
            "placeholder": "​",
            "style": "IPY_MODEL_fa95880d38e54081836e13c32b3cbb2a",
            "value": "Downloading builder script: 100%"
          }
        },
        "4f2a54d4ce9a41ecb38cde2724e6b798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48fc9092797046b980f4fb8961e2891f",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e3e739bda134f67954ffaeeac8305f4",
            "value": 4203
          }
        },
        "c9e01aeed39c4f0da94a8aeab08638db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d356ab7f2894329b37f2e79cc60d73d",
            "placeholder": "​",
            "style": "IPY_MODEL_9da8f4e523a7452994ccef93f34dd59e",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 190kB/s]"
          }
        },
        "3e0b0af4ad804600ac504d9a16570769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c102d619c38644f68989dcd07eda4cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa95880d38e54081836e13c32b3cbb2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48fc9092797046b980f4fb8961e2891f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3e739bda134f67954ffaeeac8305f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d356ab7f2894329b37f2e79cc60d73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da8f4e523a7452994ccef93f34dd59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
