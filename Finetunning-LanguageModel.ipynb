{"cells":[{"cell_type":"markdown","source":["Este notebook é um tutorial de como dar fine-tune para classificação em modelos de linguagem em datasets próprios. \n","\n","São suportados os modelos do tipo decoder e encoder-decoder. Estes dois modelos têm textos como entrada e saída. O código não suporta modelos do tipo encoder, que têm como entrada textos, e geram como saída geralmente um número (embeddings ou probabilidade da classe).\n","\n","```\n","Modelos do tipo decoder: GPT\n","Modelos do tipo encoder-decoder: T5\n","Modelos do tipo encoder: BERT\n","```"],"metadata":{"id":"ChRZNgj0Ytpo"}},{"cell_type":"markdown","metadata":{"id":"yTzNimfiFamU"},"source":["# Inicialização das variáveis"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tphHGol9EjPU","executionInfo":{"status":"ok","timestamp":1681508152686,"user_tz":180,"elapsed":5,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}}},"outputs":[],"source":["RESUME_FROM_CHECKPOINT = False\n","\n","inserir_beginoftext_token = True # Inserir um token '<|target_bos|>' separando o prompt da resposta nos modelos tipo decoder (GPT, llama)\n","MAX_TOKEN_GENERATION_LENGTH=60 # O número de tokens que será gerado, no máximo, no step de validação\n","\n","output_dir=\"/content/fine-tuned-model\"\n","\n","## Esses valores devem ser definidos para cada modelo\n","## Caso retorne o erro CUDA out of memory, diminuia o batch size\n","# model_type='decoder'\n","# model_type='encoder-decoder'\n","# BATCH_SIZE = 16\n","# EVAL_BATCH_SIZE=16\n","# dropout_rate=0.1\n","\n","transformer_model_name='thacio/ult5-pt-small'; model_type='encoder-decoder'; dropout_rate=0.0; BATCH_SIZE = 16; EVAL_BATCH_SIZE=16; #prefix_input='<|NLU|>' # '<|NLG|>'\n","\n","gradient_accumulation_steps = int(round(128//BATCH_SIZE))\n","epochs = 20"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":397,"status":"ok","timestamp":1681508153079,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"},"user_tz":180},"id":"znCm5mx5DIBI","outputId":"b7b6d335-18b3-4a71-a7b6-cc533c244900"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Apr 14 21:35:52 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","cpu_count: 2\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","import multiprocessing\n","\n","num_proc = multiprocessing.cpu_count()\n","print('cpu_count:',num_proc)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42513,"status":"ok","timestamp":1681508195588,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"},"user_tz":180},"id":"vGBw38YAFgyK","outputId":"909b9fc4-3842-4cc5-cb06-ea2f8b0e447d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Collecting huggingface-hub<1.0.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.11.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.13.4 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.13.3 transformers-4.28.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.98\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting evaluate\n","  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.0)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.11.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.22.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.65.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.13.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.27.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.11.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Installing collected packages: evaluate\n","Successfully installed evaluate-0.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.22.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (8.1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (4.65.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (2022.10.31)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (1.2.0)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=24edbda11dc611ae45c4955e2998ce6c6353d98834d6110d9093411d90a0f12d\n","  Stored in directory: /root/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}],"source":["!pip install datasets\n","!pip install transformers\n","# !pip install git+https://github.com/huggingface/transformers\n","#!pip install git+https://github.com/thacio/transformers-llama\n","!pip install sentencepiece\n","!pip install evaluate\n","!pip install rouge_score"]},{"cell_type":"markdown","source":["# Carrega o tokenizer"],"metadata":{"id":"PYokeH9Dbb5x"}},{"cell_type":"code","source":["import transformers as transformers\n","from transformers import AutoTokenizer, AutoConfig\n","\n","tokenizer = AutoTokenizer.from_pretrained(transformer_model_name,use_auth_token='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')\n","\n","# Nos modelos decoder, adicionaremos um token separando a entrada da resposta para podermos identificar e dar split na string na méetrica de validação\n","if model_type=='decoder':\n","    tokenizer.add_special_tokens({'pad_token': '<|pad|>'}) # Adicionaremos um token de pad caso o modelo não tenha (não afeta o resultado)\n","\n","    if inserir_beginoftext_token:\n","        target_bos_token='<|target_bos|>'\n","        tokenizer.add_special_tokens({ \"additional_special_tokens\": [target_bos_token] })"],"metadata":{"id":"tTnSKik6beq3","executionInfo":{"status":"ok","timestamp":1681508198286,"user_tz":180,"elapsed":2708,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}},"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["46085e174a0b47a391b5657cfb1a69cd","99fdea979b484c4e9e8f4aa935f6243e","7ae73c39501049689e55936adb5182d2","239206032e91476dbd2a6a27e7447e6c","e299bc885d814887a79aadb102c38ca7","8ecb96bb6a3d421cac12668b43474ff3","9cae200e852343e88a53f14029511709","7aa6b0549d13447a9724d2b5d9a5ba06","39f672843a1743bd8728bbfbccc069d5","288e160592264f3ea7b6ae2ffb2463df","1f2233a6868c4b09821288f815958194","d0e12eff81934b129fb2d9ba3ac33890","9dfc2e81794e451b8e39281a6c385214","f9755780ad8645c5b946f0c5cefc9d1b","96849de8b395405f8db7f01659891137","670af59092b14d81943022917ece066e","3af7ca569ce94c0b844f4b5139ab1c80","a4dda9da77a140b6874b4fe27101d2ca","f0e48ae83e8b4d69b3a4cf19883f757a","b55f14bbd9444e86822cfdfce1784ba4","ae503d8ef9f5414a8141931f64ed4fe8","95186e154b854befbf795a844109d333","5adedc05995a4655a4e750fb51bc116e","47928957b94047ef8b68b224ccd2d451","cfa301d678b545188f747ab372713d68","63091b661c904d4dbde67038cf5d21bf","b46872c461814e0c895572b5ad1e37b2","7837bbbbcc004e45a8316bfab65c371b","baed237dd7a94913a130062e450c767f","d0336d0b3ad44c539996dc52c8d5cbdd","a41b5b4f35804bcab4ce854d47555396","7ea851460bb44008b68e006882c461bc","bb493b780b7a44e4acf73fcdf9dd25ca","81b16b7eeca0463b9d4da392f107a81d","0dda8b644ed548cc8b0e55c60c4c45ae","41942b2f4c544aa093f7d8219af6a924","d24e19cafaf343469123e1fb377080e2","8c59dc3cc5f8439b8bfe3270f3a37204","10fd579ba7354f9c945c2293da8db104","1830da020e7b44ec92ac99e8b5428992","82856f6994624987bbe9daa7ccca8f20","08677a95958845a2be0f8a396d56420d","384ce7957bc14840862b5b2df2293304","43b450a56a054aae984cbf1a6f2cc672","66e77092dcbc41a8a17beaddff4247b1","22e0648c7b3448a4880658d7e7334400","7ea859bb6c664e7c957373dad62b2012","755a3ce503d14b24b878374e5fb436ae","975e1fbbac7447ac8a6ca4e2abe0a01a","0a198d90780c4060879f7d9b4a19139a","289cdeac120249929f78f4e86b286b82","ca9a725a333947a2bef7471a7efbf4a0","b4700a495d63496db240969d1cab4609","3a3e7027f17744989e30d71fe9ee914e","12aa4c6427154f3c9e4655a10b165666","fb5f2d8f46474b8a97716fa8778b087b","2ff346c6db624f99b137019b664db6ca","75423237a1ad48f4be855f8282070186","4f858d2246b140d8b4f654604c0381c2","2469d78ee78941b29512298b074b4513","199971d24d914b3e813f6512a8dd6bbc","5849cf867a6f4cb3ac4f5f12abc28513","ee8c1e1f5be043418604973630d31ce0","a2268fb32b684891bf7af51f75682223","b00e79dc86454a118766765658f6216c","d1ba1dfb9b234878b394c9ce496082c1"]},"outputId":"2c6c5b5d-21e2-40d0-d6ba-84b49136a504"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/324 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46085e174a0b47a391b5657cfb1a69cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/831k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0e12eff81934b129fb2d9ba3ac33890"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/490k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5adedc05995a4655a4e750fb51bc116e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.19M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81b16b7eeca0463b9d4da392f107a81d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.88k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66e77092dcbc41a8a17beaddff4247b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.48k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb5f2d8f46474b8a97716fa8778b087b"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Carrega o modelo"],"metadata":{"id":"C5N2ZCTKq8N8"}},{"cell_type":"code","source":["import transformers\n","from transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM\n","import torch\n","\n","if model_type=='encoder-decoder':\n","    # model = AutoModelForSeq2SeqLM.from_pretrained(transformer_model_name)\n","    model = AutoModelForSeq2SeqLM.from_pretrained(transformer_model_name,dropout_rate=dropout_rate)\n","\n","elif model_type=='decoder':\n","    model = AutoModelForCausalLM.from_pretrained(transformer_model_name)\n","else:\n","    raise ValueError('tipo de arquitetura deve ser \"decoder\" ou \"encoder-decoder')\n","\n","model.resize_token_embeddings(len(tokenizer))\n","model.max_length=MAX_TOKEN_GENERATION_LENGTH\n","\n","# context_length é o tamanho máximo do modelo\n","try:\n","    context_length=model.config.n_positions\n","except:\n","    context_length=model.config.max_position_embeddings\n","\n","print(model.config)\n","model_size = sum(t.numel() for t in model.parameters())\n","print(f\"Model size: {model_size/1000**2:.1f}M parameters\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807,"referenced_widgets":["3fa181c02c58412b964e767f2bc4d34f","2ea4ae61c2694da69ff596b5f5a622c5","5d99b78ffd0448af89530575abfbd641","d1785fefb2e947b0801ce034d0fc1ab8","8c9bdc1c64e44afe9a7948a581915520","3b9a817ccb684c868dfaf671e71ddd44","132971d19b53423b8b2249bcecbca32b","45f8ca44ac3f4b319f6c8bf8120dd630","d92ec40a04764806ad33251a55fa5238","acf63908a53942c69c4efddaf4b8db57","327eeaed23d0448989fe5e01ecdd4836","73bb7ace48d14c74851de885c4c3b562","0afcd0b42e744456a4e0e9f427e0c7cc","6c5300c7574e4c18a307d2265085bbe7","34a23829484e469782ba0d30a1e6950a","030515850dec4c22b14098729ecddea5","2e22762d27d24183951f55d3f192385e","98edfb4dc01341189be15cc66c889e8f","31bdbbb1ded644cfb0fbfff46305d738","1705cb325f5847c8aea016c594d4d6d4","4d9353c526d74cc3a8d3bcf367138ffa","83216cd704f04b9fbbf3f1e2ccf7f556","0ff2ef672b5345aaa31b0dd9da539793","8c1a22f1931e43dc9015d9923b2112bd","bd3585a1477a4f86a23dcb35496bb692","c43eb5ec48ca4baabf72d1401a340b89","04589852349e45748bef9fbcdb212502","cdd4475579e44f51808a613e2dfa8755","fd799e47a6234f3f8700c50b2c072d03","24dc11be763f4e52bb48a8cfd073a5a7","6fa177b5d1014132be340ef85165677d","c0436f0222904554b7be11c197ea3c3a","bd6247d1a4834eb8b49d81c54d5be2d4"]},"id":"r-XWDOhKq8mu","executionInfo":{"status":"ok","timestamp":1681508212837,"user_tz":180,"elapsed":14553,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}},"outputId":"0e73e027-decd-49dc-df0d-2f3387a31e3b"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/890 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fa181c02c58412b964e767f2bc4d34f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/330M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73bb7ace48d14c74851de885c4c3b562"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ff2ef672b5345aaa31b0dd9da539793"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["T5Config {\n","  \"_name_or_path\": \"thacio/ult5-pt-small\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"bos_token_id\": 50257,\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"silu\",\n","  \"dropout_rate\": 0.0,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-silu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 1024,\n","  \"num_decoder_layers\": 6,\n","  \"num_heads\": 8,\n","  \"num_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50361\n","}\n","\n","Model size: 82.4M parameters\n"]}]},{"cell_type":"markdown","source":["# Cria e processa o dataset"],"metadata":{"id":"4amVUH6_Ocen"}},{"cell_type":"markdown","source":["##Faz o download dos datasets.\n","\n","Um arquivo tsv é um arquivo csv, porém usa como separador a tabulação \\t em vez de vírgula"],"metadata":{"id":"7c5dNM_XQJmK"}},{"cell_type":"code","source":["import os\n","\n","!wget 'https://github.com/ju-resplande/PLUE/raw/master/datasets/MRPC/train.tsv' -O train.tsv\n","!wget 'https://github.com/ju-resplande/PLUE/raw/master/datasets/MRPC/dev.tsv' -O validation.tsv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwybZlhjOgLw","executionInfo":{"status":"ok","timestamp":1681508213496,"user_tz":180,"elapsed":671,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}},"outputId":"ded64a66-86f7-427f-a480-9b216a9d9d8e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-04-14 21:36:52--  https://github.com/ju-resplande/PLUE/raw/master/datasets/MRPC/train.tsv\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/ju-resplande/PLUE/master/datasets/MRPC/train.tsv [following]\n","--2023-04-14 21:36:52--  https://raw.githubusercontent.com/ju-resplande/PLUE/master/datasets/MRPC/train.tsv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1011446 (988K) [text/plain]\n","Saving to: ‘train.tsv’\n","\n","train.tsv           100%[===================>] 987.74K  --.-KB/s    in 0.008s  \n","\n","2023-04-14 21:36:52 (124 MB/s) - ‘train.tsv’ saved [1011446/1011446]\n","\n","--2023-04-14 21:36:53--  https://github.com/ju-resplande/PLUE/raw/master/datasets/MRPC/dev.tsv\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/ju-resplande/PLUE/master/datasets/MRPC/dev.tsv [following]\n","--2023-04-14 21:36:53--  https://raw.githubusercontent.com/ju-resplande/PLUE/master/datasets/MRPC/dev.tsv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 114080 (111K) [text/plain]\n","Saving to: ‘validation.tsv’\n","\n","validation.tsv      100%[===================>] 111.41K  --.-KB/s    in 0.002s  \n","\n","2023-04-14 21:36:53 (66.9 MB/s) - ‘validation.tsv’ saved [114080/114080]\n","\n"]}]},{"cell_type":"markdown","source":["## Carrega o dataset pelo pandas"],"metadata":{"id":"D94NhlPKRBgn"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# O arquivo dá erro ao carregar algumas linhas, então utilizaremos on_bad_lines='skip' para pulá-las\n","df_train = pd.read_csv('train.tsv', sep='\\t', header=0,  on_bad_lines='skip')\n","df_validation = pd.read_csv('validation.tsv', sep='\\t', header=0, on_bad_lines='skip')\n","df_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"fWxkTYeURI0G","executionInfo":{"status":"ok","timestamp":1681508214300,"user_tz":180,"elapsed":807,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}},"outputId":"89c9b2a3-d406-4deb-e50b-8df2117cb064"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Quality    #1 ID    #2 ID  \\\n","0        1   702876   702977   \n","1        0  2108705  2108831   \n","2        1  1330381  1330521   \n","3        0  3344667  3344648   \n","4        1  1236820  1236712   \n","\n","                                           #1 String  \\\n","0  Amrozi acusou seu irmão, a quem chamou de \"tes...   \n","1  Yucaipa possuía a Dominick 's antes de vender ...   \n","2  Eles publicaram um anúncio na Internet em 10 d...   \n","3  Por volta de 0335 GMT, as ações da Tab subiram...   \n","4  As ações subiram US $ 2,11, ou cerca de 11%, p...   \n","\n","                                           #2 String  \n","0  Referindo-se a ele como apenas \"a testemunha\",...  \n","1  Yucaipa comprou a Dominick em 1995 por US $ 69...  \n","2  Em 10 de junho, os proprietários do navio havi...  \n","3  As ações da Tab saltaram 20 centavos, ou 4,6%,...  \n","4  As ações da PG & E Corp subiram US $ 1,63 ou 8...  "],"text/html":["\n","  <div id=\"df-cfa2d6b9-c505-4c39-abf2-08b2cc5face7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Quality</th>\n","      <th>#1 ID</th>\n","      <th>#2 ID</th>\n","      <th>#1 String</th>\n","      <th>#2 String</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>702876</td>\n","      <td>702977</td>\n","      <td>Amrozi acusou seu irmão, a quem chamou de \"tes...</td>\n","      <td>Referindo-se a ele como apenas \"a testemunha\",...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>2108705</td>\n","      <td>2108831</td>\n","      <td>Yucaipa possuía a Dominick 's antes de vender ...</td>\n","      <td>Yucaipa comprou a Dominick em 1995 por US $ 69...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1330381</td>\n","      <td>1330521</td>\n","      <td>Eles publicaram um anúncio na Internet em 10 d...</td>\n","      <td>Em 10 de junho, os proprietários do navio havi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3344667</td>\n","      <td>3344648</td>\n","      <td>Por volta de 0335 GMT, as ações da Tab subiram...</td>\n","      <td>As ações da Tab saltaram 20 centavos, ou 4,6%,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1236820</td>\n","      <td>1236712</td>\n","      <td>As ações subiram US $ 2,11, ou cerca de 11%, p...</td>\n","      <td>As ações da PG &amp; E Corp subiram US $ 1,63 ou 8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfa2d6b9-c505-4c39-abf2-08b2cc5face7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cfa2d6b9-c505-4c39-abf2-08b2cc5face7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cfa2d6b9-c505-4c39-abf2-08b2cc5face7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## Carrega o dataset na biblioteca datasets do huggingface\n","\n","https://huggingface.co/docs/datasets/loading"],"metadata":{"id":"VsbKG5ieQVpx"}},{"cell_type":"code","source":["import datasets\n","from datasets import load_dataset\n","\n","ds_train = datasets.Dataset.from_pandas(df_train)\n","ds_validation = datasets.Dataset.from_pandas(df_validation)\n","\n","ds = datasets.DatasetDict({\n","    'train' : ds_train,\n","    'validation' : ds_validation\n","    })\n","\n","ds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-z6o0o5hQWXW","executionInfo":{"status":"ok","timestamp":1681508215033,"user_tz":180,"elapsed":734,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}},"outputId":"f8ad6d1a-f282-4072-d11b-3ff628fef18a"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Quality', '#1 ID', '#2 ID', '#1 String', '#2 String'],\n","        num_rows: 3549\n","    })\n","    validation: Dataset({\n","        features: ['Quality', '#1 ID', '#2 ID', '#1 String', '#2 String'],\n","        num_rows: 388\n","    })\n","})"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["print('exemplo do dataset')\n","ds['train'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"znX9S7DXSyMd","executionInfo":{"status":"ok","timestamp":1681508215033,"user_tz":180,"elapsed":5,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}},"outputId":"de496f99-a651-4ab5-ac7e-50a35e29b60e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["exemplo do dataset\n"]},{"output_type":"execute_result","data":{"text/plain":["{'Quality': 1,\n"," '#1 ID': 702876,\n"," '#2 ID': 702977,\n"," '#1 String': 'Amrozi acusou seu irmão, a quem chamou de \"testemunha\", de distorcer deliberadamente suas evidências.',\n"," '#2 String': 'Referindo-se a ele como apenas \"a testemunha\", Amrozi acusou seu irmão de distorcer deliberadamente suas evidências.'}"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## Converte o dataset para textos de input e labels\n","\n","Os modelos do tipo decoder (gpt2) e enconder-decoder (t5) geram textos, então devemos converter tudo em texto. Se por acaso os rótulos forem numéricos (0,1,...), também devem ser convertido para textos. Textos representativos dos rótulos costumam gerar melhores resultados do que rótulos de string '0' e '1'. \n","\n","Já os modelos do tipo encoder (BERT) geralmente tem como saída as classes númericas. (há exceção e tem como usar o BERT como decoder, porém não é usual)\n","\n","---\n","\n","O dataset MRPC é composto da sentença 1 e sentença 2, e o rótulo é se as sentenças são paráfrases ou não.\n","\n","Dessa forma, faremos a transformação do exemplo:\n","\n","```\n","{\n","'#1 String': 'Amrozi acusou seu irmão, a quem chamou de \"testemunha\", de distorcer deliberadamente suas evidências.',\n","'#2 String': 'Referindo-se a ele como apenas \"a testemunha\", Amrozi acusou seu irmão de distorcer deliberadamente suas evidências.'\n","'Quality': 1\n","}\n","```\n","\n","Para\n","\n","```\n","{\n","'text' : 'mrpc sentença 1: Amrozi acusou seu irmão, a quem chamou de \"testemunha\", de distorcer deliberadamente suas evidências. sentença 2: Referindo-se a ele como apenas \"a testemunha\", Amrozi acusou seu irmão de distorcer deliberadamente suas evidências.'\n","'label': 'equivalentes'\n","}\n","```\n","com acréscimo dos tokens necessários (eos_token e taget_bos_token em decoders)"],"metadata":{"id":"CrkGqkVYXK1a"}},{"cell_type":"markdown","source":["Para fazer essa conversão, usaremos a função map do huggingface datasets.\n","\n","https://huggingface.co/docs/datasets/process"],"metadata":{"id":"6l0fwJnrYnaS"}},{"cell_type":"markdown","source":["### Função map para decoders (gpt2, llama)"],"metadata":{"id":"FYyND0e8ZJtz"}},{"cell_type":"code","source":["def mrpc_map_dec_function(examples):\n","    new_examples = { 'text':[], 'labels':[]}\n","   \n","    first_key=list(examples.keys())[0]\n","    for i in range(0,len(examples[first_key])):\n","        input=f'mrpc sentença 1: {examples[\"#1 String\"][i]}'\n","        input+=f' sentença 2: {examples[\"#2 String\"][i]}'\n","        if examples['Quality'][i] == 0:\n","            label = 'diferentes'\n","        elif examples['Quality'][i] == 1:\n","            label = 'equivalentes'\n","\n","        if inserir_beginoftext_token:\n","            input += target_bos_token\n","\n","        # adicionamos o o token de fim de texto ao label\n","        label += tokenizer.eos_token\n","\n","        new_examples['text'].append(input)\n","        new_examples['labels'].append(label)\n","\n","    return new_examples\n","\n","if model_type=='decoder':\n","    ds_processado = ds.map(\n","          mrpc_map_dec_function,\n","          batched=True,\n","          batch_size=1_000,\n","          remove_columns=ds['train'].column_names,\n","          num_proc=2\n","      )    \n","    print(ds_processado)\n","    print(ds_processado['train'][0])"],"metadata":{"id":"sqT6OS2SXMzy","executionInfo":{"status":"ok","timestamp":1681508215034,"user_tz":180,"elapsed":4,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["###Função map para modelos encoder-decoders (t5, ul2)"],"metadata":{"id":"HxeKws6IZONT"}},{"cell_type":"code","source":["# define a função de map para ser aplicada ao dataset\n","def mrpc_map_enc_dec_function(examples):\n","    new_examples = { 'text':[], 'labels':[]}\n","   \n","    first_key=list(examples.keys())[0]\n","    for i in range(0,len(examples[first_key])):\n","        input=f'mrpc sentença 1: {examples[\"#1 String\"][i]}'\n","        input+=f' sentença 2: {examples[\"#2 String\"][i]}'\n","        input+=' As duas sentenças são equivalentes ou diferentes?'\n","        if examples['Quality'][i] == 0:\n","            label = 'diferentes'\n","        elif examples['Quality'][i] == 1:\n","            label = 'equivalentes'\n","\n","        label += tokenizer.eos_token\n","                \n","        if 'prefix_input' in globals() and prefix_input!=None and len(prefix_input)>0:            \n","            input = prefix_input + input\n","\n","        new_examples['text'].append(input)\n","        new_examples['labels'].append(label)\n","\n","    return new_examples\n","\n","# aplica a função\n","if model_type=='encoder-decoder':\n","    ds_processado = ds.map(\n","          mrpc_map_enc_dec_function,\n","          batched=True,\n","          batch_size=1_000,\n","          remove_columns=ds['train'].column_names,\n","          num_proc=2\n","      )    \n","    print(ds_processado)\n","    print(ds_processado['train'][0])"],"metadata":{"id":"8fOz_3xIZaod","executionInfo":{"status":"ok","timestamp":1681508215893,"user_tz":180,"elapsed":863,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}},"colab":{"base_uri":"https://localhost:8080/","height":228,"referenced_widgets":["cd950c4ce2d04e6e82404eaf6e728a99","7b2990f7b8714861a0fc05d623c15bea","3c1b332f09cc4f778e31c24813287107","0a1f61bae7ca4d4f8ac0487a92806d9d","59cc33ac9b744b1d9814bb19499f7f1e","f91f8399d42d4f0a89c6e07c6efde5a9","8d65ffffc35f4676989ae56666d93478","5d820d34c459495d891e30997c031fe6","82c153c244144ec7bbd3c1b9b438c66d","16b0cad8714d46bbbe1478338f22d7a1","11e75cd6cc1a469f8864c9e06f4f94bc","199ae5eef3a94186b954e0d439314755","ae23c749c50447e7ba37c8d8d3048969","cd8bc80f391840349c5dc86ddfe98e80","f5ed93b090a44487a2863949d3283442","c5db2071953e4db8affd5928849c49b9","e3899fb0510f466996759f54261d03f7","73330a2c467548dca95212d763999b07","c14324d451264514839ae2faec86d662","95adac1de81b458aa02260fbb270131f","b67697478afe47e29e0143bbc0b43f0a","4b205e1d57254306bdc2523d00b45c42"]},"outputId":"eedb6637-b613-4b6e-9dff-485155ccbe98"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/3549 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd950c4ce2d04e6e82404eaf6e728a99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/388 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"199ae5eef3a94186b954e0d439314755"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'labels'],\n","        num_rows: 3549\n","    })\n","    validation: Dataset({\n","        features: ['text', 'labels'],\n","        num_rows: 388\n","    })\n","})\n","{'text': 'mrpc sentença 1: Amrozi acusou seu irmão, a quem chamou de \"testemunha\", de distorcer deliberadamente suas evidências. sentença 2: Referindo-se a ele como apenas \"a testemunha\", Amrozi acusou seu irmão de distorcer deliberadamente suas evidências. As duas sentenças são equivalentes ou diferentes?', 'labels': 'equivalentes<|endoftext|>'}\n"]}]},{"cell_type":"markdown","source":["## Tokeniza o dataset"],"metadata":{"id":"wNFmOqH1gxH8"}},{"cell_type":"code","source":["\n","is_validation_ds = False\n","def tokenize_dataset(examples):\n","\n","    examples['input_ids']=tokenizer(examples['text'],\n","                      return_attention_mask=False,\n","                      truncation=True,\n","                      max_length=context_length,\n","                      )['input_ids']\n","\n","    examples['labels']=tokenizer(examples['labels'],\n","                      return_attention_mask=False,\n","                      truncation=True,\n","                      max_length=context_length,\n","                      )['input_ids']\n","\n","    # Insere o eos_token_id caso não tenha sido inserido anteriormente\n","    for i, label in enumerate(examples['labels']):\n","        try:\n","            if label[len(label)-1]!=tokenizer.eos_token_id:\n","                examples['labels'][i] += [tokenizer.eos_token_id]            \n","        except:\n","            # Caso por erro do dataset não haja label\n","            examples['labels'][i] = [tokenizer.eos_token_id]            \n","            pass\n","        # Nos decoders Nos datasets de validação, precisamos inseri\n","        if model_type=='decoder' and is_validation_ds:\n","            examples['labels'][i] = [500_000] + label\n","\n","    return examples\n","\n","ds_tokenizado = datasets.DatasetDict({'train':None, 'validation': None})\n","\n","ds_tokenizado['train'] = ds_processado['train'].map(\n","    tokenize_dataset,\n","    batched=True,\n","    batch_size=1_000,\n","    num_proc=2,\n","    remove_columns=['text']\n",")\n","\n","is_validation_ds = True\n","ds_tokenizado['validation'] = ds_processado['validation'].map(\n","    tokenize_dataset,\n","    batched=True,\n","    batch_size=1_000,\n","    num_proc=2,\n","    remove_columns=['text']\n",")\n","is_validation_ds = False\n","\n","print(ds_tokenizado)\n","print(ds_tokenizado['train'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228,"referenced_widgets":["c6fcbd3c4fb04e9d984b65cf65d8d3e7","e9268ba7ec3f492ba345bfea13f6d536","c0b32a28d0974288b9b3a521ae6f1bfb","e557e7b39a3c451fa34b077707ca8615","2f7ef4ea6dea4f85863643bb08e59b44","cfcd456619bd4019878ef39d35e05619","01144f208cbd493990a975d51a7db7cb","c87f69e894b34ce3b7f8051cda1540b5","bb835b4d14824f99a88d265dd68c3608","8e293dbea2744172b72ce3d64d959de8","46558d6f637249cd815518d4945d7d5d","279b81ceb61b4a2e86bd48233d65b268","b0f3b4c2afdd48729bd55dcfe25fd5d2","03c3326da7744e3c8abca58754b0a2f3","df19ad8872d74e40a8a18c18acb3bcac","9e441800f76c4e968e953e6646325f9d","ab6c3b974b574482b6bc4d1029f0297f","74799bd1d8054dacb91451456cb18edc","108f40d04cfb4adf98178632f3667910","ed7ad6e3a2bc43d3af10096e7d65d0c8","fa9de8e66c304c74bb66552a042a8288","681472f8617744cea8ad2c19e6f33153"]},"id":"6WN39BKahKkK","executionInfo":{"status":"ok","timestamp":1681508218129,"user_tz":180,"elapsed":2239,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}},"outputId":"f4d4d975-e868-452a-bb9a-a7024038ad27"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/3549 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6fcbd3c4fb04e9d984b65cf65d8d3e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/388 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"279b81ceb61b4a2e86bd48233d65b268"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['labels', 'input_ids'],\n","        num_rows: 3549\n","    })\n","    validation: Dataset({\n","        features: ['labels', 'input_ids'],\n","        num_rows: 388\n","    })\n","})\n","{'labels': [15012, 1919, 744, 1], 'input_ids': [78, 83, 81, 68, 15910, 308, 27, 946, 287, 6554, 22069, 510, 3040, 13, 262, 2578, 7164, 260, 431, 85, 512, 316, 3915, 806, 260, 19907, 2860, 31195, 956, 9706, 15, 15910, 327, 27, 37222, 763, 14, 369, 262, 532, 409, 1091, 431, 66, 21005, 806, 946, 287, 6554, 22069, 510, 3040, 260, 19907, 2860, 31195, 956, 9706, 15, 739, 1195, 32144, 643, 22558, 537, 2333, 32]}\n"]}]},{"cell_type":"markdown","source":["## Cria a métrica de validação do dataset"],"metadata":{"id":"aKU7rUqKj20s"}},{"cell_type":"markdown","source":["### Métrica de avaliação do dataset\n","\n","Par ao dataset MRPC, usaremos a acurácia, ou seja, o acerto exato do rótulo"],"metadata":{"id":"yEwkAkdFkih_"}},{"cell_type":"code","source":["from evaluate import load\n","\n","def mrpc_metric(predictions,labels):\n","    exact_match_metric = load(\"exact_match\")\n","    result = exact_match_metric.compute(predictions=predictions,references=labels)\n","\n","    return {'mrpc_acc': result['exact_match']}"],"metadata":{"id":"UriMY_ZOkAt-","executionInfo":{"status":"ok","timestamp":1681508226425,"user_tz":180,"elapsed":8298,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### Função de computo da métrica com geração de texto\n","\n","No caso de decoders, a função da métrica de avaliação recebe o texto inteiro 'input + labels', então precisamos processar a string recebida pela função para separar o input do label para, em seguida, calcular a métrica"],"metadata":{"id":"fI48SeJrj6pd"}},{"cell_type":"code","source":["import numpy as np\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    result = {}    \n","\n","    predictions=list(predictions)\n","    labels=list(labels)\n","\n","    if model_type=='decoder':\n","        target_bos_token_id = tokenizer.convert_tokens_to_ids(target_bos_token)\n","\n","        for i in range(len(predictions)):\n","            # # Split nos  tokens gerados considerando o target_bos_token para identificar o input e o label\n","            index = np.where(predictions[i] == target_bos_token_id)[0][0]\n","            predictions[i] = predictions[i][index+1:] # texto gerado após o input\n","            \n","            # # Remove os valores até o eos_token_id ou o pad_token_id\n","            # # (o model.generate no evaluate está gerando texto além dos pads, o que está causando erro no processamento abaixo)\n","            # split_index = None\n","            # for j in range(len(predictions[i])):\n","            #     if predictions[i][j] == tokenizer.eos_token_id:\n","            #         split_index = j + 1\n","            #         break\n","            #     elif predictions[i][j] == tokenizer.pad_token_id and split_index is None:\n","            #         split_index = j\n","            # if split_index is not None:\n","            #     predictions[i] = predictions[i][:split_index]\n","\n","    \n","    for i in range(0,len(labels)):\n","        # remove  os ids que não podem ser decodificados\n","        labels[i] = list(filter(lambda x: x!= -100, labels[i]))\n","        predictions[i] = list(filter(lambda x: x!= -100, predictions[i]))\n","\n","        # remove os pad_tokens\n","        labels[i] = list(filter(lambda x: x!= tokenizer.pad_token_id, labels[i]))\n","        predictions[i] = list(filter(lambda x: x!= tokenizer.pad_token_id, predictions[i]))\n","\n","        # remove os eos_tokens\n","        labels[i] = list(filter(lambda x: x!= tokenizer.eos_token_id, labels[i]))\n","        predictions[i] = list(filter(lambda x: x!= tokenizer.eos_token_id, predictions[i]))\n","\n","    \n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","\n","    # print('Decoded labels')\n","    # print(decoded_labels)\n","    # print('Decoded predictions')\n","    # print(decoded_preds)\n","    \n","    result = mrpc_metric(decoded_preds,decoded_labels)\n","\n","    return result"],"metadata":{"id":"f_gQBsMUkHKn","executionInfo":{"status":"ok","timestamp":1681508226426,"user_tz":180,"elapsed":16,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rmOgli9IKGE7"},"source":["# DataCollator para Decoders (Causal Language Modeling)\n","\n","Os modelos encoder-decoder possuem o input e os outputs separados.\n","\n","Nos modelos decoder, só a um vetor de texto.\n","No finetunning para classificação dos modelos decoders, colocaremos para o modelo apenas prever o texto do label. Assim, a parte do input será atribuída um label de valor -100, assim o modelo saberá que não deve ser calculado *loss* para esses tokens."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"JqCUqkohKLnH","executionInfo":{"status":"ok","timestamp":1681508226426,"user_tz":180,"elapsed":14,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}}},"outputs":[],"source":["import random\n","import warnings\n","from collections.abc import Mapping\n","from dataclasses import dataclass\n","from random import randint\n","from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n","\n","import numpy as np\n","\n","from transformers.models.bert import BertTokenizer, BertTokenizerFast\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n","from transformers.utils import PaddingStrategy\n","\n","import torch\n","import transformers.data.data_collator\n","from transformers.data.data_collator import _torch_collate_batch\n","\n","\n","class DataCollatorMixin:\n","    def __call__(self, features, return_tensors=None):\n","        if return_tensors is None:\n","            return_tensors = self.return_tensors\n","        if return_tensors == \"tf\":\n","            return self.tf_call(features)\n","        elif return_tensors == \"pt\":\n","            return self.torch_call(features)\n","        elif return_tensors == \"np\":\n","            return self.numpy_call(features)\n","        else:\n","            raise ValueError(f\"Framework '{return_tensors}' not recognized!\")\n","\n","@dataclass\n","class DataCollatorWithPaddingModified:\n","    \"\"\"\n","    Data collator that will dynamically pad the inputs received.\n","    Args:\n","        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n","            The tokenizer used for encoding the data.\n","        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n","            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n","            among:\n","            - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n","              sequence is provided).\n","            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n","              acceptable input length for the model if that argument is not provided.\n","            - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n","        max_length (`int`, *optional*):\n","            Maximum length of the returned list and optionally padding length (see above).\n","        pad_to_multiple_of (`int`, *optional*):\n","            If set will pad the sequence to a multiple of the provided value.\n","            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n","            7.5 (Volta).\n","        return_tensors (`str`):\n","            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n","    \"\"\"\n","\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    return_tensors: str = \"pt\"\n","\n","    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:        \n","        inputs=[]\n","        labels=[]\n","        attention_mask=[]\n","        \n","        is_validation_dataset = (features[0]['labels'][0] > len(tokenizer))\n","        if is_validation_dataset:\n","            i = 0\n","            for feat in features:\n","                labels.append(feat['labels'][1:])\n","                inputs.append(feat['input_ids'])        \n","        else: # training datset       \n","            for feat in features:\n","                labels.append([-100] * len(feat['input_ids']) + feat['labels'])\n","                inputs.append(feat['input_ids'] + feat['labels'])\n","\n","        # artifício para dar pad nos inputs e labels ao mesmo tempo\n","        inputs = {'input_ids' : inputs + labels}\n","\n","        previous_level = transformers.logging.get_verbosity()\n","        transformers.logging.set_verbosity_error()        \n","        #####        \n","        batch = self.tokenizer.pad(\n","            inputs,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=self.return_tensors,\n","        )\n","        transformers.logging.set_verbosity(previous_level) ####\n","\n","        half_idx = len(labels)\n","\n","        batch['labels'] = batch['input_ids'][half_idx:len(batch['input_ids'])]\n","        batch['input_ids'] = batch['input_ids'][0:half_idx]\n","        batch['attention_mask'] = batch['attention_mask'][0:half_idx]\n","\n","        \n","        batch['labels'][batch['labels'] == self.tokenizer.pad_token_id] = -100\n","\n","        if \"label\" in batch:\n","            batch[\"labels\"] = batch[\"label\"]\n","            del batch[\"label\"]\n","        if \"label_ids\" in batch:\n","            batch[\"labels\"] = batch[\"label_ids\"]\n","            del batch[\"label_ids\"]\n","\n","        return batch"]},{"cell_type":"markdown","metadata":{"id":"JPYv_RDwUN91"},"source":["# Treina o modelo"]},{"cell_type":"markdown","metadata":{"id":"kdyvQDUPiBFw"},"source":["## Ajusta a classe Trainer do hugginface\n","\n","Foi alterada na classe Trainer a configuração de geração de textos de validação e silenciado os avisos na geração"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"waZy7Ee_0jvY","executionInfo":{"status":"ok","timestamp":1681508226426,"user_tz":180,"elapsed":13,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}}},"outputs":[],"source":["# https://github.com/huggingface/transformers/blob/v4.26.1/src/transformers/trainer_seq2seq.py\n","# Copyright 2020 The HuggingFace Team. All rights reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\n","from typing import Any, Dict, List, Optional, Tuple, Union\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","\n","from transformers.deepspeed import is_deepspeed_zero3_enabled\n","from transformers.trainer import Trainer\n","from transformers.trainer_utils import PredictionOutput\n","from transformers.utils import logging\n","import transformers\n","\n","\n","logger = logging.get_logger(__name__)\n","\n","class Seq2SeqTrainerDecoder(Trainer):\n","    def evaluate(\n","        self,\n","        eval_dataset: Optional[Dataset] = None,\n","        ignore_keys: Optional[List[str]] = None,\n","        metric_key_prefix: str = \"eval\",\n","        **gen_kwargs\n","    ) -> Dict[str, float]:\n","        \"\"\"\n","        Run evaluation and returns metrics.\n","        The calling script will be responsible for providing a method to compute metrics, as they are task-dependent\n","        (pass it to the init `compute_metrics` argument).\n","        You can also subclass and override this method to inject custom behavior.\n","        Args:\n","            eval_dataset (`Dataset`, *optional*):\n","                Pass a dataset if you wish to override `self.eval_dataset`. If it is an [`~datasets.Dataset`], columns\n","                not accepted by the `model.forward()` method are automatically removed. It must implement the `__len__`\n","                method.\n","            ignore_keys (`List[str]`, *optional*):\n","                A list of keys in the output of your model (if it is a dictionary) that should be ignored when\n","                gathering predictions.\n","            metric_key_prefix (`str`, *optional*, defaults to `\"eval\"`):\n","                An optional prefix to be used as the metrics key prefix. For example the metrics \"bleu\" will be named\n","                \"eval_bleu\" if the prefix is `\"eval\"` (default)\n","            max_length (`int`, *optional*):\n","                The maximum target length to use when predicting with the generate method.\n","            num_beams (`int`, *optional*):\n","                Number of beams for beam search that will be used when predicting with the generate method. 1 means no\n","                beam search.\n","            gen_kwargs:\n","                Additional `generate` specific kwargs.\n","        Returns:\n","            A dictionary containing the evaluation loss and the potential metrics computed from the predictions. The\n","            dictionary also contains the epoch number which comes from the training state.\n","        \"\"\"\n","\n","        gen_kwargs = gen_kwargs.copy()\n","        if gen_kwargs.get(\"max_length\") is None and gen_kwargs.get(\"max_new_tokens\") is None:\n","            gen_kwargs[\"max_length\"] = self.args.generation_max_length\n","        gen_kwargs[\"num_beams\"] = (\n","            gen_kwargs[\"num_beams\"] if gen_kwargs.get(\"num_beams\") is not None else self.args.generation_num_beams\n","        )\n","        self._gen_kwargs = gen_kwargs\n","\n","        return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n","\n","    def predict(\n","        self,\n","        test_dataset: Dataset,\n","        ignore_keys: Optional[List[str]] = None,\n","        metric_key_prefix: str = \"test\",\n","        **gen_kwargs\n","    ) -> PredictionOutput:\n","        \"\"\"\n","        Run prediction and returns predictions and potential metrics.\n","        Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method\n","        will also return metrics, like in `evaluate()`.\n","        Args:\n","            test_dataset (`Dataset`):\n","                Dataset to run the predictions on. If it is a [`~datasets.Dataset`], columns not accepted by the\n","                `model.forward()` method are automatically removed. Has to implement the method `__len__`\n","            ignore_keys (`List[str]`, *optional*):\n","                A list of keys in the output of your model (if it is a dictionary) that should be ignored when\n","                gathering predictions.\n","            metric_key_prefix (`str`, *optional*, defaults to `\"eval\"`):\n","                An optional prefix to be used as the metrics key prefix. For example the metrics \"bleu\" will be named\n","                \"eval_bleu\" if the prefix is `\"eval\"` (default)\n","            max_length (`int`, *optional*):\n","                The maximum target length to use when predicting with the generate method.\n","            num_beams (`int`, *optional*):\n","                Number of beams for beam search that will be used when predicting with the generate method. 1 means no\n","                beam search.\n","            gen_kwargs:\n","                Additional `generate` specific kwargs.\n","        <Tip>\n","        If your predictions or labels have different sequence lengths (for instance because you're doing dynamic\n","        padding in a token classification task) the predictions will be padded (on the right) to allow for\n","        concatenation into one array. The padding index is -100.\n","        </Tip>\n","        Returns: *NamedTuple* A namedtuple with the following keys:\n","            - predictions (`np.ndarray`): The predictions on `test_dataset`.\n","            - label_ids (`np.ndarray`, *optional*): The labels (if the dataset contained some).\n","            - metrics (`Dict[str, float]`, *optional*): The potential dictionary of metrics (if the dataset contained\n","              labels).\n","        \"\"\"\n","\n","        gen_kwargs = gen_kwargs.copy()\n","        if gen_kwargs.get(\"max_length\") is None and gen_kwargs.get(\"max_new_tokens\") is None:\n","            gen_kwargs[\"max_length\"] = self.args.generation_max_length\n","        gen_kwargs[\"num_beams\"] = (\n","            gen_kwargs[\"num_beams\"] if gen_kwargs.get(\"num_beams\") is not None else self.args.generation_num_beams\n","        )\n","        self._gen_kwargs = gen_kwargs\n","\n","        return super().predict(test_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n","\n","    def prediction_step(\n","        self,\n","        model: nn.Module,\n","        inputs: Dict[str, Union[torch.Tensor, Any]],\n","        prediction_loss_only: bool,\n","        ignore_keys: Optional[List[str]] = None,\n","    ) -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n","        \"\"\"\n","        Perform an evaluation step on `model` using `inputs`.\n","        Subclass and override to inject custom behavior.\n","        Args:\n","            model (`nn.Module`):\n","                The model to evaluate.\n","            inputs (`Dict[str, Union[torch.Tensor, Any]]`):\n","                The inputs and targets of the model.\n","                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n","                argument `labels`. Check your model's documentation for all accepted arguments.\n","            prediction_loss_only (`bool`):\n","                Whether or not to return the loss only.\n","        Return:\n","            Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]: A tuple with the loss, logits and\n","            labels (each being optional).\n","        \"\"\"\n","\n","        if not self.args.predict_with_generate or prediction_loss_only:\n","            return super().prediction_step(\n","                model, inputs, prediction_loss_only=prediction_loss_only, ignore_keys=ignore_keys\n","            )\n","\n","        has_labels = \"labels\" in inputs\n","        inputs = self._prepare_inputs(inputs)\n","\n","        # XXX: adapt synced_gpus for fairscale as well\n","        gen_kwargs = self._gen_kwargs.copy()\n","        if gen_kwargs.get(\"max_length\") is None and gen_kwargs.get(\"max_new_tokens\") is None:\n","            gen_kwargs[\"max_length\"] = self.model.config.max_length\n","        gen_kwargs[\"num_beams\"] = (\n","            gen_kwargs[\"num_beams\"] if gen_kwargs.get(\"num_beams\") is not None else self.model.config.num_beams\n","        )\n","        default_synced_gpus = True if is_deepspeed_zero3_enabled() else False\n","        gen_kwargs[\"synced_gpus\"] = (\n","            gen_kwargs[\"synced_gpus\"] if gen_kwargs.get(\"synced_gpus\") is not None else default_synced_gpus\n","        )\n","\n","        if \"attention_mask\" in inputs:\n","            gen_kwargs[\"attention_mask\"] = inputs.get(\"attention_mask\", None)\n","        if \"global_attention_mask\" in inputs:\n","            gen_kwargs[\"global_attention_mask\"] = inputs.get(\"global_attention_mask\", None)\n","\n","        # prepare generation inputs\n","        # some encoder-decoder models can have varying encoder's and thus\n","        # varying model input names\n","        if hasattr(self.model, \"encoder\") and self.model.encoder.main_input_name != self.model.main_input_name:\n","            generation_inputs = inputs[self.model.encoder.main_input_name]\n","        else:\n","            generation_inputs = inputs[self.model.main_input_name]\n","\n","        ##### Alteração\n","        gen_kwargs[\"max_new_tokens\"] = MAX_TOKEN_GENERATION_LENGTH\n","        del gen_kwargs[\"max_length\"]\n","        gen_kwargs[\"eos_token_id\"]=self.tokenizer.eos_token_id\n","        previous_level = transformers.logging.get_verbosity()\n","        transformers.logging.set_verbosity_error()        \n","        #####        \n","        generated_tokens = self.model.generate(\n","            generation_inputs,\n","            **gen_kwargs\n","        )\n","        \n","        \n","\n","        # in case the batch is shorter than max length, the output should be padded\n","        if gen_kwargs.get(\"max_length\") is not None and generated_tokens.shape[-1] < gen_kwargs[\"max_length\"]:\n","            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_length\"])\n","        elif gen_kwargs.get(\"max_new_tokens\") is not None and generated_tokens.shape[-1] < (\n","            gen_kwargs[\"max_new_tokens\"] + 1\n","        ):\n","            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_new_tokens\"] + 1)\n","\n","        with torch.no_grad():\n","            if has_labels:\n","                with self.compute_loss_context_manager():\n","                    outputs = model(**inputs)\n","                if self.label_smoother is not None:\n","                    loss = self.label_smoother(outputs, inputs[\"labels\"]).mean().detach()\n","                else:\n","                    loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n","            else:\n","                loss = None\n","\n","        if self.args.prediction_loss_only:\n","            return (loss, None, None)\n","\n","        if has_labels:\n","            labels = inputs[\"labels\"]\n","            if gen_kwargs.get(\"max_length\") is not None and labels.shape[-1] < gen_kwargs[\"max_length\"]:\n","                labels = self._pad_tensors_to_max_len(labels, gen_kwargs[\"max_length\"])\n","            elif gen_kwargs.get(\"max_new_tokens\") is not None and labels.shape[-1] < (\n","                gen_kwargs[\"max_new_tokens\"] + 1\n","            ):\n","                labels = self._pad_tensors_to_max_len(labels, (gen_kwargs[\"max_new_tokens\"] + 1))\n","        else:\n","            labels = None\n","        transformers.logging.set_verbosity(previous_level) ####\n","        return (loss, generated_tokens, labels)\n","\n","    def _pad_tensors_to_max_len(self, tensor, max_length):\n","        if self.tokenizer is not None and hasattr(self.tokenizer, \"pad_token_id\"):\n","            # If PAD token is not defined at least EOS token has to be defined\n","            pad_token_id = (\n","                self.tokenizer.pad_token_id if self.tokenizer.pad_token_id is not None else self.tokenizer.eos_token_id\n","            )\n","        else:\n","            if self.model.config.pad_token_id is not None:\n","                pad_token_id = self.model.config.pad_token_id\n","            else:\n","                raise ValueError(\"Pad_token_id must be set in the configuration of the model, in order to pad tensors\")\n","\n","        padded_tensor = pad_token_id * torch.ones(\n","            (tensor.shape[0], max_length), dtype=tensor.dtype, device=tensor.device\n","        )\n","        padded_tensor[:, : tensor.shape[-1]] = tensor\n","        return padded_tensor"]},{"cell_type":"markdown","metadata":{"id":"1jgrlcn-C_Gs"},"source":["## Treina o model"]},{"cell_type":"markdown","source":["Treino"],"metadata":{"id":"MdWH5_LQht_n"}},{"cell_type":"code","execution_count":17,"metadata":{"id":"3AcBhmIJBory","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bf58c72f554b43bb96a85a5ea7921330","810e65142a2e4d6086753af491905319","2bb6d7aa3fe349909c6c18febc01f464","d9bee9151e44476d8d53883dd80f6706","09189743e65b465ca013fa6bc1049d78","4a52019ee0e14c679d9f81edd0301cc4","0fc5d984eeef4a8bb273e85e128a7bd6","17a0a07c239a4041a5d720a228b6df9b","4eac0a8739254f688bb9d693bd9d08b6","98d723b051244570ac0567c463f022e1","3c48a8a611df44f4aa3deab4e0283738"]},"executionInfo":{"status":"ok","timestamp":1681508752058,"user_tz":180,"elapsed":525644,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}},"outputId":"ac3fc732-a26a-4e9e-f2d9-6bd91aacb2a7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [540/540 08:34, Epoch 19/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Mrpc Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.943200</td>\n","      <td>0.220186</td>\n","      <td>0.487113</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.158600</td>\n","      <td>0.164321</td>\n","      <td>0.677835</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.136900</td>\n","      <td>0.133332</td>\n","      <td>0.770619</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.106500</td>\n","      <td>0.173322</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.069100</td>\n","      <td>0.185994</td>\n","      <td>0.729381</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.025200</td>\n","      <td>0.209836</td>\n","      <td>0.780928</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.009200</td>\n","      <td>0.212559</td>\n","      <td>0.806701</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.005900</td>\n","      <td>0.306476</td>\n","      <td>0.775773</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.003200</td>\n","      <td>0.310725</td>\n","      <td>0.798969</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.001200</td>\n","      <td>0.326508</td>\n","      <td>0.770619</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.000600</td>\n","      <td>0.333479</td>\n","      <td>0.793814</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.000100</td>\n","      <td>0.436100</td>\n","      <td>0.786082</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.000000</td>\n","      <td>0.439178</td>\n","      <td>0.783505</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.000000</td>\n","      <td>0.439107</td>\n","      <td>0.780928</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.000000</td>\n","      <td>0.444311</td>\n","      <td>0.783505</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.000000</td>\n","      <td>0.448775</td>\n","      <td>0.786082</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.000000</td>\n","      <td>0.452368</td>\n","      <td>0.786082</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.000000</td>\n","      <td>0.456463</td>\n","      <td>0.786082</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.000000</td>\n","      <td>0.460318</td>\n","      <td>0.786082</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.000000</td>\n","      <td>0.461633</td>\n","      <td>0.786082</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/5.67k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf58c72f554b43bb96a85a5ea7921330"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=540, training_loss=0.07380735663882323, metrics={'train_runtime': 518.3928, 'train_samples_per_second': 136.923, 'train_steps_per_second': 1.042, 'total_flos': 2496526352646144.0, 'train_loss': 0.07380735663882323, 'epoch': 19.46})"]},"metadata":{},"execution_count":17}],"source":["from transformers import TrainingArguments, Trainer, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from transformers import DataCollatorForLanguageModeling\n","from transformers import DataCollatorForSeq2Seq\n","import torch\n","import os\n","\n","\n","if model_type=='decoder':\n","    data_collator = DataCollatorWithPaddingModified(tokenizer,max_length=model.config.n_positions,pad_to_multiple_of=8,return_tensors='pt')\n","    compute_metrics=compute_metrics\n","    learning_rate=1e-4\n","elif model_type=='encoder-decoder':\n","    data_collator = DataCollatorForSeq2Seq(tokenizer,model=model,max_length=context_length,pad_to_multiple_of=8,return_tensors='pt')\n","    compute_metrics=compute_metrics\n","    learning_rate=1e-4\n","\n","args = Seq2SeqTrainingArguments(\n","    output_dir=output_dir,\n","    save_strategy=\"epoch\",        \n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","\n","    evaluation_strategy=\"epoch\",\n","    eval_steps=1,\n","\n","    logging_strategy=\"epoch\",\n","    logging_steps=1,\n","    predict_with_generate=True,\n","    # resume_from_checkpoint=RESUME_FROM_CHECKPOINT,    \n","\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=EVAL_BATCH_SIZE,\n","    gradient_accumulation_steps = gradient_accumulation_steps,        \n","\n","    num_train_epochs=epochs,\n","\n","    lr_scheduler_type=\"constant\",\n","    learning_rate=learning_rate,\n","    weight_decay=0.1,\n","    \n","    fp16=True,\n","    fp16_full_eval=True,\n","    dataloader_num_workers=1,\n","    # push_to_hub=True,\n","    # hub_token='token_do_huggingface',\n","    # hub_strategy=\"checkpoint\",\n","    # hub_model_id=\"nome_do_usuario/nome_do_mudelo\",\n",")\n","\n","\n","trainer = Seq2SeqTrainerDecoder(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=args,\n","    data_collator=data_collator,\n","    train_dataset=ds_tokenizado[\"train\"],\n","    eval_dataset=ds_tokenizado[\"validation\"],\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train(resume_from_checkpoint=RESUME_FROM_CHECKPOINT)"]},{"cell_type":"markdown","metadata":{"id":"hOSO48cz5XJG"},"source":["# Gera texto pelo modelo finetune"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"kKf0PGC-BFWm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681508828460,"user_tz":180,"elapsed":1775,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}},"outputId":"66a13629-c3c9-4b73-f0bf-9ce415a1e1f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["input: mrpc sentença 1: Amrozi acusou seu irmão, a quem chamou de \"testemunha\", de distorcer deliberadamente suas evidências. sentença 2: Referindo-se a ele como apenas \"a testemunha\", Amrozi acusou seu irmão de distorcer deliberadamente suas evidências. As duas sentenças são equivalentes ou diferentes?\n","generated: ['<|pad|>equivalentes<|endoftext|>']\n","\n","input: mrpc sentença 1: Yucaipa possuía a Dominick 's antes de vender a rede para a Safeway em 1998 por US $ 2,5 bilhões. sentença 2: Yucaipa comprou a Dominick em 1995 por US $ 693 milhões e a vendeu à Safeway por US $ 1,8 bilhão em 1998. As duas sentenças são equivalentes ou diferentes?\n","generated: ['<|pad|>diferentes<|endoftext|>']\n","\n","input: mrpc sentença 1: Ele disse que o negócio de tortas de serviços alimentícios não se encaixa na estratégia de crescimento da empresa a longo prazo. sentença 2: O negócio de torta de serviços alimentícios não se encaixa em nossa estratégia de crescimento a longo prazo.\n","0\t2029631\t2029565\tMagnarelli disse que Racicot odiava o regime iraquiano e esperava usar seus longos anos de treinamento na guerra.\tSua esposa disse que ele estava 100% atrás de George Bush\" e esperava usar seus anos de treinamento na guerra. As duas sentenças são equivalentes ou diferentes?\n","generated: ['<|pad|>diferentes<|endoftext|>']\n","\n","input: mrpc sentença 1: O dólar ficou em 116,92 ienes contra o iene, estável na sessão, e em 1,2891 contra o franco suíço, também estável. sentença 2: O dólar ficou em 116,78 ienes JPY =, praticamente estável na sessão e em 1,2871 contra o franco suíço CHF =, queda de 0,1%. As duas sentenças são equivalentes ou diferentes?\n","generated: ['<|pad|>diferentes<|endoftext|>']\n","\n"]}],"source":["import torch\n","from transformers import pipeline\n","import pandas as pd\n","\n","# cpu\n","texts=[]\n","\n","for key in ds_processado.keys():\n","    texts.append(ds_processado[key][0]['text'])\n","    texts.append(ds_processado[key][1]['text'])\n","model.to('cpu')\n","pred=[]\n","\n","previous_level = transformers.logging.get_verbosity()\n","transformers.logging.set_verbosity_error()        \n","\n","for text in texts:    \n","    pred.append(tokenizer.batch_decode(model.generate(tokenizer.encode(text,return_tensors='pt'),max_new_tokens=20,eos_token_id=tokenizer.eos_token_id)))\n","\n","transformers.logging.set_verbosity(previous_level) ####\n","\n","for i in range(0,len(texts)):\n","    print('input:',texts[i])\n","    print('generated:',pred[i])\n","    print('')"]},{"cell_type":"markdown","metadata":{"id":"hrOh9N02Su-_"},"source":["# Desconectar do COLAB"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"BbosINFq2VhP","executionInfo":{"status":"ok","timestamp":1681508841577,"user_tz":180,"elapsed":256,"user":{"displayName":"Thacio Scandaroli","userId":"03379062830633082032"}}},"outputs":[],"source":["from google.colab import runtime\n","\n","runtime.unassign()"]},{"cell_type":"code","source":[],"metadata":{"id":"YIFKtqzLhM6S"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOVfEoAMXLI7Z86Ot/YWUJK"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"46085e174a0b47a391b5657cfb1a69cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99fdea979b484c4e9e8f4aa935f6243e","IPY_MODEL_7ae73c39501049689e55936adb5182d2","IPY_MODEL_239206032e91476dbd2a6a27e7447e6c"],"layout":"IPY_MODEL_e299bc885d814887a79aadb102c38ca7"}},"99fdea979b484c4e9e8f4aa935f6243e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ecb96bb6a3d421cac12668b43474ff3","placeholder":"​","style":"IPY_MODEL_9cae200e852343e88a53f14029511709","value":"Downloading (…)okenizer_config.json: 100%"}},"7ae73c39501049689e55936adb5182d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aa6b0549d13447a9724d2b5d9a5ba06","max":324,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39f672843a1743bd8728bbfbccc069d5","value":324}},"239206032e91476dbd2a6a27e7447e6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_288e160592264f3ea7b6ae2ffb2463df","placeholder":"​","style":"IPY_MODEL_1f2233a6868c4b09821288f815958194","value":" 324/324 [00:00&lt;00:00, 12.5kB/s]"}},"e299bc885d814887a79aadb102c38ca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ecb96bb6a3d421cac12668b43474ff3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cae200e852343e88a53f14029511709":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7aa6b0549d13447a9724d2b5d9a5ba06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39f672843a1743bd8728bbfbccc069d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"288e160592264f3ea7b6ae2ffb2463df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f2233a6868c4b09821288f815958194":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0e12eff81934b129fb2d9ba3ac33890":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9dfc2e81794e451b8e39281a6c385214","IPY_MODEL_f9755780ad8645c5b946f0c5cefc9d1b","IPY_MODEL_96849de8b395405f8db7f01659891137"],"layout":"IPY_MODEL_670af59092b14d81943022917ece066e"}},"9dfc2e81794e451b8e39281a6c385214":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3af7ca569ce94c0b844f4b5139ab1c80","placeholder":"​","style":"IPY_MODEL_a4dda9da77a140b6874b4fe27101d2ca","value":"Downloading (…)olve/main/vocab.json: 100%"}},"f9755780ad8645c5b946f0c5cefc9d1b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0e48ae83e8b4d69b3a4cf19883f757a","max":831237,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b55f14bbd9444e86822cfdfce1784ba4","value":831237}},"96849de8b395405f8db7f01659891137":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae503d8ef9f5414a8141931f64ed4fe8","placeholder":"​","style":"IPY_MODEL_95186e154b854befbf795a844109d333","value":" 831k/831k [00:00&lt;00:00, 11.7MB/s]"}},"670af59092b14d81943022917ece066e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3af7ca569ce94c0b844f4b5139ab1c80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4dda9da77a140b6874b4fe27101d2ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0e48ae83e8b4d69b3a4cf19883f757a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b55f14bbd9444e86822cfdfce1784ba4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae503d8ef9f5414a8141931f64ed4fe8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95186e154b854befbf795a844109d333":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5adedc05995a4655a4e750fb51bc116e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47928957b94047ef8b68b224ccd2d451","IPY_MODEL_cfa301d678b545188f747ab372713d68","IPY_MODEL_63091b661c904d4dbde67038cf5d21bf"],"layout":"IPY_MODEL_b46872c461814e0c895572b5ad1e37b2"}},"47928957b94047ef8b68b224ccd2d451":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7837bbbbcc004e45a8316bfab65c371b","placeholder":"​","style":"IPY_MODEL_baed237dd7a94913a130062e450c767f","value":"Downloading (…)olve/main/merges.txt: 100%"}},"cfa301d678b545188f747ab372713d68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0336d0b3ad44c539996dc52c8d5cbdd","max":489555,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a41b5b4f35804bcab4ce854d47555396","value":489555}},"63091b661c904d4dbde67038cf5d21bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ea851460bb44008b68e006882c461bc","placeholder":"​","style":"IPY_MODEL_bb493b780b7a44e4acf73fcdf9dd25ca","value":" 490k/490k [00:00&lt;00:00, 12.7MB/s]"}},"b46872c461814e0c895572b5ad1e37b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7837bbbbcc004e45a8316bfab65c371b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baed237dd7a94913a130062e450c767f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0336d0b3ad44c539996dc52c8d5cbdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a41b5b4f35804bcab4ce854d47555396":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ea851460bb44008b68e006882c461bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb493b780b7a44e4acf73fcdf9dd25ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81b16b7eeca0463b9d4da392f107a81d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0dda8b644ed548cc8b0e55c60c4c45ae","IPY_MODEL_41942b2f4c544aa093f7d8219af6a924","IPY_MODEL_d24e19cafaf343469123e1fb377080e2"],"layout":"IPY_MODEL_8c59dc3cc5f8439b8bfe3270f3a37204"}},"0dda8b644ed548cc8b0e55c60c4c45ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10fd579ba7354f9c945c2293da8db104","placeholder":"​","style":"IPY_MODEL_1830da020e7b44ec92ac99e8b5428992","value":"Downloading (…)/main/tokenizer.json: 100%"}},"41942b2f4c544aa093f7d8219af6a924":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82856f6994624987bbe9daa7ccca8f20","max":2193802,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08677a95958845a2be0f8a396d56420d","value":2193802}},"d24e19cafaf343469123e1fb377080e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_384ce7957bc14840862b5b2df2293304","placeholder":"​","style":"IPY_MODEL_43b450a56a054aae984cbf1a6f2cc672","value":" 2.19M/2.19M [00:00&lt;00:00, 30.4MB/s]"}},"8c59dc3cc5f8439b8bfe3270f3a37204":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10fd579ba7354f9c945c2293da8db104":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1830da020e7b44ec92ac99e8b5428992":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82856f6994624987bbe9daa7ccca8f20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08677a95958845a2be0f8a396d56420d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"384ce7957bc14840862b5b2df2293304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43b450a56a054aae984cbf1a6f2cc672":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66e77092dcbc41a8a17beaddff4247b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22e0648c7b3448a4880658d7e7334400","IPY_MODEL_7ea859bb6c664e7c957373dad62b2012","IPY_MODEL_755a3ce503d14b24b878374e5fb436ae"],"layout":"IPY_MODEL_975e1fbbac7447ac8a6ca4e2abe0a01a"}},"22e0648c7b3448a4880658d7e7334400":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a198d90780c4060879f7d9b4a19139a","placeholder":"​","style":"IPY_MODEL_289cdeac120249929f78f4e86b286b82","value":"Downloading (…)in/added_tokens.json: 100%"}},"7ea859bb6c664e7c957373dad62b2012":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca9a725a333947a2bef7471a7efbf4a0","max":2881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4700a495d63496db240969d1cab4609","value":2881}},"755a3ce503d14b24b878374e5fb436ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a3e7027f17744989e30d71fe9ee914e","placeholder":"​","style":"IPY_MODEL_12aa4c6427154f3c9e4655a10b165666","value":" 2.88k/2.88k [00:00&lt;00:00, 172kB/s]"}},"975e1fbbac7447ac8a6ca4e2abe0a01a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a198d90780c4060879f7d9b4a19139a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"289cdeac120249929f78f4e86b286b82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca9a725a333947a2bef7471a7efbf4a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4700a495d63496db240969d1cab4609":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a3e7027f17744989e30d71fe9ee914e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12aa4c6427154f3c9e4655a10b165666":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb5f2d8f46474b8a97716fa8778b087b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ff346c6db624f99b137019b664db6ca","IPY_MODEL_75423237a1ad48f4be855f8282070186","IPY_MODEL_4f858d2246b140d8b4f654604c0381c2"],"layout":"IPY_MODEL_2469d78ee78941b29512298b074b4513"}},"2ff346c6db624f99b137019b664db6ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_199971d24d914b3e813f6512a8dd6bbc","placeholder":"​","style":"IPY_MODEL_5849cf867a6f4cb3ac4f5f12abc28513","value":"Downloading (…)cial_tokens_map.json: 100%"}},"75423237a1ad48f4be855f8282070186":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee8c1e1f5be043418604973630d31ce0","max":2478,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2268fb32b684891bf7af51f75682223","value":2478}},"4f858d2246b140d8b4f654604c0381c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b00e79dc86454a118766765658f6216c","placeholder":"​","style":"IPY_MODEL_d1ba1dfb9b234878b394c9ce496082c1","value":" 2.48k/2.48k [00:00&lt;00:00, 115kB/s]"}},"2469d78ee78941b29512298b074b4513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"199971d24d914b3e813f6512a8dd6bbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5849cf867a6f4cb3ac4f5f12abc28513":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee8c1e1f5be043418604973630d31ce0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2268fb32b684891bf7af51f75682223":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b00e79dc86454a118766765658f6216c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1ba1dfb9b234878b394c9ce496082c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fa181c02c58412b964e767f2bc4d34f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ea4ae61c2694da69ff596b5f5a622c5","IPY_MODEL_5d99b78ffd0448af89530575abfbd641","IPY_MODEL_d1785fefb2e947b0801ce034d0fc1ab8"],"layout":"IPY_MODEL_8c9bdc1c64e44afe9a7948a581915520"}},"2ea4ae61c2694da69ff596b5f5a622c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b9a817ccb684c868dfaf671e71ddd44","placeholder":"​","style":"IPY_MODEL_132971d19b53423b8b2249bcecbca32b","value":"Downloading (…)lve/main/config.json: 100%"}},"5d99b78ffd0448af89530575abfbd641":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45f8ca44ac3f4b319f6c8bf8120dd630","max":890,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d92ec40a04764806ad33251a55fa5238","value":890}},"d1785fefb2e947b0801ce034d0fc1ab8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acf63908a53942c69c4efddaf4b8db57","placeholder":"​","style":"IPY_MODEL_327eeaed23d0448989fe5e01ecdd4836","value":" 890/890 [00:00&lt;00:00, 15.8kB/s]"}},"8c9bdc1c64e44afe9a7948a581915520":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b9a817ccb684c868dfaf671e71ddd44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"132971d19b53423b8b2249bcecbca32b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45f8ca44ac3f4b319f6c8bf8120dd630":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d92ec40a04764806ad33251a55fa5238":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"acf63908a53942c69c4efddaf4b8db57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"327eeaed23d0448989fe5e01ecdd4836":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73bb7ace48d14c74851de885c4c3b562":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0afcd0b42e744456a4e0e9f427e0c7cc","IPY_MODEL_6c5300c7574e4c18a307d2265085bbe7","IPY_MODEL_34a23829484e469782ba0d30a1e6950a"],"layout":"IPY_MODEL_030515850dec4c22b14098729ecddea5"}},"0afcd0b42e744456a4e0e9f427e0c7cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e22762d27d24183951f55d3f192385e","placeholder":"​","style":"IPY_MODEL_98edfb4dc01341189be15cc66c889e8f","value":"Downloading pytorch_model.bin: 100%"}},"6c5300c7574e4c18a307d2265085bbe7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31bdbbb1ded644cfb0fbfff46305d738","max":329746697,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1705cb325f5847c8aea016c594d4d6d4","value":329746697}},"34a23829484e469782ba0d30a1e6950a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d9353c526d74cc3a8d3bcf367138ffa","placeholder":"​","style":"IPY_MODEL_83216cd704f04b9fbbf3f1e2ccf7f556","value":" 330M/330M [00:05&lt;00:00, 57.0MB/s]"}},"030515850dec4c22b14098729ecddea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e22762d27d24183951f55d3f192385e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98edfb4dc01341189be15cc66c889e8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31bdbbb1ded644cfb0fbfff46305d738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1705cb325f5847c8aea016c594d4d6d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d9353c526d74cc3a8d3bcf367138ffa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83216cd704f04b9fbbf3f1e2ccf7f556":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ff2ef672b5345aaa31b0dd9da539793":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c1a22f1931e43dc9015d9923b2112bd","IPY_MODEL_bd3585a1477a4f86a23dcb35496bb692","IPY_MODEL_c43eb5ec48ca4baabf72d1401a340b89"],"layout":"IPY_MODEL_04589852349e45748bef9fbcdb212502"}},"8c1a22f1931e43dc9015d9923b2112bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdd4475579e44f51808a613e2dfa8755","placeholder":"​","style":"IPY_MODEL_fd799e47a6234f3f8700c50b2c072d03","value":"Downloading (…)neration_config.json: 100%"}},"bd3585a1477a4f86a23dcb35496bb692":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24dc11be763f4e52bb48a8cfd073a5a7","max":172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6fa177b5d1014132be340ef85165677d","value":172}},"c43eb5ec48ca4baabf72d1401a340b89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0436f0222904554b7be11c197ea3c3a","placeholder":"​","style":"IPY_MODEL_bd6247d1a4834eb8b49d81c54d5be2d4","value":" 172/172 [00:00&lt;00:00, 4.46kB/s]"}},"04589852349e45748bef9fbcdb212502":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdd4475579e44f51808a613e2dfa8755":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd799e47a6234f3f8700c50b2c072d03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24dc11be763f4e52bb48a8cfd073a5a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fa177b5d1014132be340ef85165677d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0436f0222904554b7be11c197ea3c3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd6247d1a4834eb8b49d81c54d5be2d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd950c4ce2d04e6e82404eaf6e728a99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b2990f7b8714861a0fc05d623c15bea","IPY_MODEL_3c1b332f09cc4f778e31c24813287107","IPY_MODEL_0a1f61bae7ca4d4f8ac0487a92806d9d"],"layout":"IPY_MODEL_59cc33ac9b744b1d9814bb19499f7f1e"}},"7b2990f7b8714861a0fc05d623c15bea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f91f8399d42d4f0a89c6e07c6efde5a9","placeholder":"​","style":"IPY_MODEL_8d65ffffc35f4676989ae56666d93478","value":"Map (num_proc=2):  50%"}},"3c1b332f09cc4f778e31c24813287107":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d820d34c459495d891e30997c031fe6","max":3549,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82c153c244144ec7bbd3c1b9b438c66d","value":3549}},"0a1f61bae7ca4d4f8ac0487a92806d9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16b0cad8714d46bbbe1478338f22d7a1","placeholder":"​","style":"IPY_MODEL_11e75cd6cc1a469f8864c9e06f4f94bc","value":" 1775/3549 [00:00&lt;00:00, 9123.33 examples/s]"}},"59cc33ac9b744b1d9814bb19499f7f1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"f91f8399d42d4f0a89c6e07c6efde5a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d65ffffc35f4676989ae56666d93478":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d820d34c459495d891e30997c031fe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82c153c244144ec7bbd3c1b9b438c66d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16b0cad8714d46bbbe1478338f22d7a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11e75cd6cc1a469f8864c9e06f4f94bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"199ae5eef3a94186b954e0d439314755":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ae23c749c50447e7ba37c8d8d3048969","IPY_MODEL_cd8bc80f391840349c5dc86ddfe98e80","IPY_MODEL_f5ed93b090a44487a2863949d3283442"],"layout":"IPY_MODEL_c5db2071953e4db8affd5928849c49b9"}},"ae23c749c50447e7ba37c8d8d3048969":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3899fb0510f466996759f54261d03f7","placeholder":"​","style":"IPY_MODEL_73330a2c467548dca95212d763999b07","value":"Map (num_proc=2):  50%"}},"cd8bc80f391840349c5dc86ddfe98e80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c14324d451264514839ae2faec86d662","max":388,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95adac1de81b458aa02260fbb270131f","value":388}},"f5ed93b090a44487a2863949d3283442":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b67697478afe47e29e0143bbc0b43f0a","placeholder":"​","style":"IPY_MODEL_4b205e1d57254306bdc2523d00b45c42","value":" 194/388 [00:00&lt;00:00, 1441.59 examples/s]"}},"c5db2071953e4db8affd5928849c49b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"e3899fb0510f466996759f54261d03f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73330a2c467548dca95212d763999b07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c14324d451264514839ae2faec86d662":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95adac1de81b458aa02260fbb270131f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b67697478afe47e29e0143bbc0b43f0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b205e1d57254306bdc2523d00b45c42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6fcbd3c4fb04e9d984b65cf65d8d3e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9268ba7ec3f492ba345bfea13f6d536","IPY_MODEL_c0b32a28d0974288b9b3a521ae6f1bfb","IPY_MODEL_e557e7b39a3c451fa34b077707ca8615"],"layout":"IPY_MODEL_2f7ef4ea6dea4f85863643bb08e59b44"}},"e9268ba7ec3f492ba345bfea13f6d536":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfcd456619bd4019878ef39d35e05619","placeholder":"​","style":"IPY_MODEL_01144f208cbd493990a975d51a7db7cb","value":"Map (num_proc=2): 100%"}},"c0b32a28d0974288b9b3a521ae6f1bfb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c87f69e894b34ce3b7f8051cda1540b5","max":3549,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb835b4d14824f99a88d265dd68c3608","value":3549}},"e557e7b39a3c451fa34b077707ca8615":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e293dbea2744172b72ce3d64d959de8","placeholder":"​","style":"IPY_MODEL_46558d6f637249cd815518d4945d7d5d","value":" 3549/3549 [00:01&lt;00:00, 3028.41 examples/s]"}},"2f7ef4ea6dea4f85863643bb08e59b44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"cfcd456619bd4019878ef39d35e05619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01144f208cbd493990a975d51a7db7cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c87f69e894b34ce3b7f8051cda1540b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb835b4d14824f99a88d265dd68c3608":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e293dbea2744172b72ce3d64d959de8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46558d6f637249cd815518d4945d7d5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"279b81ceb61b4a2e86bd48233d65b268":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0f3b4c2afdd48729bd55dcfe25fd5d2","IPY_MODEL_03c3326da7744e3c8abca58754b0a2f3","IPY_MODEL_df19ad8872d74e40a8a18c18acb3bcac"],"layout":"IPY_MODEL_9e441800f76c4e968e953e6646325f9d"}},"b0f3b4c2afdd48729bd55dcfe25fd5d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab6c3b974b574482b6bc4d1029f0297f","placeholder":"​","style":"IPY_MODEL_74799bd1d8054dacb91451456cb18edc","value":"Map (num_proc=2):  50%"}},"03c3326da7744e3c8abca58754b0a2f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_108f40d04cfb4adf98178632f3667910","max":388,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed7ad6e3a2bc43d3af10096e7d65d0c8","value":388}},"df19ad8872d74e40a8a18c18acb3bcac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa9de8e66c304c74bb66552a042a8288","placeholder":"​","style":"IPY_MODEL_681472f8617744cea8ad2c19e6f33153","value":" 194/388 [00:00&lt;00:00, 945.33 examples/s]"}},"9e441800f76c4e968e953e6646325f9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"ab6c3b974b574482b6bc4d1029f0297f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74799bd1d8054dacb91451456cb18edc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"108f40d04cfb4adf98178632f3667910":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed7ad6e3a2bc43d3af10096e7d65d0c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa9de8e66c304c74bb66552a042a8288":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"681472f8617744cea8ad2c19e6f33153":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf58c72f554b43bb96a85a5ea7921330":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_810e65142a2e4d6086753af491905319","IPY_MODEL_2bb6d7aa3fe349909c6c18febc01f464","IPY_MODEL_d9bee9151e44476d8d53883dd80f6706"],"layout":"IPY_MODEL_09189743e65b465ca013fa6bc1049d78"}},"810e65142a2e4d6086753af491905319":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a52019ee0e14c679d9f81edd0301cc4","placeholder":"​","style":"IPY_MODEL_0fc5d984eeef4a8bb273e85e128a7bd6","value":"Downloading builder script: 100%"}},"2bb6d7aa3fe349909c6c18febc01f464":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17a0a07c239a4041a5d720a228b6df9b","max":5669,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4eac0a8739254f688bb9d693bd9d08b6","value":5669}},"d9bee9151e44476d8d53883dd80f6706":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98d723b051244570ac0567c463f022e1","placeholder":"​","style":"IPY_MODEL_3c48a8a611df44f4aa3deab4e0283738","value":" 5.67k/5.67k [00:00&lt;00:00, 218kB/s]"}},"09189743e65b465ca013fa6bc1049d78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a52019ee0e14c679d9f81edd0301cc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fc5d984eeef4a8bb273e85e128a7bd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17a0a07c239a4041a5d720a228b6df9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eac0a8739254f688bb9d693bd9d08b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98d723b051244570ac0567c463f022e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c48a8a611df44f4aa3deab4e0283738":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}